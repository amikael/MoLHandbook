\section{Adjunction Grammars}
\label{kap4-5}
%
%
%
In this and the next section we shall concern ourselves with some
alternative types of grammars which are all (more or less) equivalent
to head grammars. These are the tree adjoining grammars (TAGs), CCGs
(which are some refined version of the adjunction grammars of
Section~\ref{kap1}.\ref{kap1-4} and the grammars $\CCG(\mathbf{Q})$
of Section~\ref{kap3}.\ref{kap3-2}, respectively) and the so--called
linear index grammars.

Let us return to the concept of tree adjoining grammars.
These are pairs $G = \auf \BC, N, A, \BA\zu$,
where $\BC$ is the set of centre trees and
$\BA$ a set of adjunction trees. In an adjunction
tree a node is called \textbf{central}
%%%
\index{node!central}%%
%%%
if it is above the distinguished leaf or identical to it.

It is advantageous to define a naming scheme for nodes in 
an adjunction tree. Let $\GT = \auf T, <_T, \sqsubset_T, \ell_T\zu$ 
be a centre tree. Then put $N(T) := T$. If adjoining 
$\GA = \auf A, <_A, \sqsubset_A, \ell_A\zu$ at $x$ to $\GT$
yields $\GU = \auf U, <_U, \sqsubset_U, \ell_U\zu$ 
then
%%%
\begin{equation}
\label{eq:55rec}
N(\GU) := (N(T) - \{x\}) \cup \{x \conc \GA \conc v : v \in A\}
\end{equation}
%%%
Let $H$ be the set of all nodes of centre or adjunction trees. 
Then $N(\GT) \subseteq  H \cdot (\GA \cdot H)^{\ast}$. Furthermore, 
as is inductively verified, $N(\GT)$ is prefix free. Thus, as $x$ 
gets replaced by strings of which $x$ is a suffix, no name that 
is added equals any name in $N(\GU)$. So, the naming scheme is 
unique. Moreover, it turns out that the structure of $\GT$ is 
uniquely determined by $N(\GT)$. The map that identifies $x \in T$ 
with its name is called $\nu$. Put $N := N(\GT)$ and
%%
\begin{equation}
%%%
\index{$\GN(\GT)$}%%%
%%%
\GN(\GT) := \auf N, <^N, \sqsubset^N, \ell^N\zu 
\end{equation}
%%
If $\vec{\sigma} = \vec{\gamma}\conc\GA \conc j$, let 
$\ell^N(\vec{\sigma}) := X$ for the unique $X$ which is the label 
of the node $j$ in $\GA$. Second, put $\vec{\sigma} \sqsubset_N 
\vec{\tau}$ if $\vec{\sigma} = \vec{\gamma}\conc j \conc \GA\conc %
\vec{\eta}$ and $\vec{\tau} = \vec{\gamma}\conc j'\conc \GA \conc %
\vec{\theta}$ for certain $\vec{\gamma}$, $\vec{\eta}$, $\vec{\theta}$, 
$\GA$ and $j \neq j'$ such that $j \sqsubset j'$. Third, 
$\vec{\sigma} < \vec{\tau}$ if $\vec{\sigma} = \vec{\gamma}\conc j %
\conc\GA\conc\vec{\eta}$ and 
$\vec{\tau} = \vec{\gamma}\conc j' \conc \GA\conc \vec{\theta}$ 
for certain $\vec{\gamma}$, $\vec{\eta}$, $\vec{\theta}$, $\GA$ 
and $j \neq j'$, such that (a) $j < j'$, (b) $j'$ and every node 
of $\vec{\theta}$ is central in its corresponding adjunction tree.
%%%
\begin{prop}
$\nu$ is an isomorphism from $\GT$ onto $\GN(\GT)$.
\end{prop}
%%%
Thus, we basically only need to define $N(\GT)$. It turns out 
that the sets $N(\GT)$ are the sets of leaves of a CFG.
For the sake of simplicity we assume that the set of nodes of
$\GB$ is the set of numbers $j(\GB) = \{0, 1, \dotsc, j(\GB)-1\}$.
$j_{\ast} := \max \{j(\GB) : \GB \in \BA \cup \BC\}$. The terminals 
are the numbers $< j_{\ast}$. The nonterminals are pairs $(i,\GB)$ 
where $\GB$ is a tree and $i < j_{\ast}$. The start symbols are 
$(0,\GC)$, $\GC \in \BC$. First, we shall define the 
grammar$^{\ast}$ $D(G)$. 
%%%
\index{$D(G)$}%%
%%%
The rules are of this form.
%%
\begin{align}
\label{eq:rules} (j,\GA) & \pf X_0 \quad X_1 \dotsb X_{j(\GA)-1} 
\end{align}
%%
where \eqref{eq:rules} is to be seen as rule a scheme: for every $\GA$
and every admissible $j$ we may choose whether $X_i$ 
is $i$ or $(i,\GB_i)$ ($i < j(\GA)$) for some tree 
$\GB_i$ which can be adjoined at $i$ in $\GA$. This grammar$^{\ast}$
%%%
\index{derivation grammar}%%
\index{grammar!derivation}%%
%%%
we denote by $D(G)$ and call it the \textbf{derivation grammar}.
%%%
\index{derivation}%%
%%%
A \textbf{derivation} for $G$ is simply a tree generated by 
$D(G)$. The following is clear: trees from $D(G)$ are in one--to--one
correspondence with their sets of leaves, which in turn 
define tree of the adjunction grammar. It should be said that 
the correspondence is not always biunique. (This is so since 
any given tree may have different derivations, and these 
get matched with nonisomorphic trees in $D(G)$. However, 
each derivation tree maps to exactly one tree of $G$ modulo 
isomorphism.)

TAGs differ from the unregulated tree adjunction grammars in 
that they allow to specify
%%
\begin{dingautolist}{192}
\item whether adjunction at a certain node is licit,
\item which trees may be adjoined at which node, and
\item whether adjunction is obligatory at certain nodes.
\end{dingautolist}
%%
We shall show that \ding{192} increases the generative power
but \ding{193} and \ding{194} do not in presence of \ding{192}.
To establish control over derivations, we shall have to change 
our definitions a little bit. We begin with \ding{192}.
To control for the possiblity of adjunction, we assume that 
the category symbols are now of the form $a$, $a \in A$, or $X$ 
and $X^{\triangledown}$ 
%%%
\index{$X^{\triangledown}$}%%%
%%%
respectively, where $X \in N$. Centre and adjunction trees are 
defined as before. Adjunction is also
defined as before. There is a leaf $i$ which has the same 
label as the root (all other leaves carry terminal labels). However, 
no adjunction is licit at nodes with label $X^{\triangledown}$. 
Notice that root and distinguished leaf must carry the same nonterminal, 
it is not admitted that one carries $X$ while the other has 
$X^{\triangledown}$. Even if we admitted that, this would not increase 
the generative capacity. Using such grammars one can generate 
the language $\{\mbox{\tt a}^n \mbox{\tt b}^n\mbox{\tt c}^n\mbox{\tt d}^n :
n \in \omega\}$. Figure~\ref{fig:abcdn} shows such a grammar. The 
centre tree is shown to the left, the adjunction tree to the right.
%%
\begin{figure}
\begin{center}
\begin{picture}(10,17)
\put(5,6){\makebox(0,0){$\varepsilon$}}
\put(5,7){\makebox(0,0){$\bullet$}}
\put(5,10){\makebox(0,0){$\bullet$}}
\put(5,7){\line(0,1){3}}
\put(5,11){\makebox(0,0){\tt S}}
\end{picture}
%%%
\qquad
%%%
\begin{picture}(10,17)
\put(5,2){\line(0,1){12}}
\put(5,5){\line(-1,-1){3}}
\put(5,5){\line(1,-1){3}}
\put(5,11){\line(-1,-1){3}}
\put(5,11){\line(1,-1){3}}
\put(5,2){\makebox(0,0){$\bullet$}}
\put(5,5){\makebox(0,0){$\bullet$}}
\put(5,8){\makebox(0,0){$\bullet$}}
\put(5,11){\makebox(0,0){$\bullet$}}
\put(5,14){\makebox(0,0){$\bullet$}}
\put(2,2){\makebox(0,0){$\bullet$}}
\put(2,8){\makebox(0,0){$\bullet$}}
\put(8,2){\makebox(0,0){$\bullet$}}
\put(8,8){\makebox(0,0){$\bullet$}}
\put(5,1){\makebox(0,0){$\mbox{\tt S}^{\triangledown}$}}
\put(5,15){\makebox(0,0){$\mbox{\tt S}^{\triangledown}$}}
\put(2,1){\makebox(0,0){\tt b}}
\put(2,7){\makebox(0,0){\tt a}}
\put(8,1){\makebox(0,0){\tt c}}
\put(8,7){\makebox(0,0){\tt d}}
\put(4,11){\makebox(0,0){\tt T}}
\put(4,8){\makebox(0,0){\tt S}}
\put(4,5){\makebox(0,0){\tt T}}
\end{picture}
\end{center}
\caption{A Tree Adjoining Grammar for $\{\mbox{\tt a}^n\mbox{\tt b}^n%
\mbox{\tt c}^n\mbox{\tt d}^n : n \in \omega\}$}
\label{fig:abcdn}
\end{figure}
%%
It is not hard to show that one can generally reduce such grammars 
to those where both the root and the leaf carry labels of the form
$X^{\triangledown}$. Namely, if the root does not carry an adjunction 
prohibition, but, say, a label $X \in N$, then add a new root which has 
label $X^{\triangledown}$, and similarly for the distinguished leaf.
Also, notice that adjunction prohibition for interior nodes of 
adjunction trees can be implemented by changing their label to a 
newly added nonterminal. Trivially, no tree can be adjoined there.
%%
\begin{defn}
%%%
\index{tree adjoining grammar!standard}%%
\index{TAG}%%
%%%
A \textbf{standard tree adjoining grammar} (or simply a \textbf{TAG}) 
is an adjunction grammar in which the adjunction trees carry an
adjunction prohibition at the root and the distinguished leaf.
\end{defn}
%%
Now let us turn to \ding{193} and \ding{194}. It is possible to 
specify in standard TAGs whether adjunction is obligatory and 
which trees may be adjoined. So, we also have a function $f$ which 
maps all nodes with nonterminal labels to sets of adjunction trees. 
(If for some $i$ $f(i) = \varnothing$ then that node effectively 
has an adjunction prohibition.) We can simulate this as follows.
Let $\BA$ be the set of adjunction trees. We think of the
nonterminals as labels of the form $\auf X, \GT\zu$
and $\auf X, \GT\zu^{\triangledown}$, respectively, where $X \in N$
and $\GT \in \BA$. A (centre or adjunction) tree $\GT$ is replaced 
by all trees $\GT'$ on the same set of nodes, where $i$ carries
the label $\auf X,\GU\zu$ if $i$ had label $X$ in $\GT$ if
$\GU \in f(i)$, and $\auf X,\GU\zu^{\triangledown}$ if
$i$ has the label $X^{\triangledown}$ in $\GT$. However, if $i$ 
is the root, it will only get the label $\auf i, \GT\zu^{\triangledown}$. 
The second element says nothing but which tree is going to be 
adjoined next. This eliminates the second point from the list, 
as we can reduce the grammars by keeping the tree structure.

Now let us turn to the last point, the obligation for adjunction.
We can implement this by introducing labels of the form
$X^{\bullet}$.  (Since obligation and prohibition to adjoin
are exclusive, $\bullet$ occurs only when $\triangledown$ does not.)
A tree is complete only if there are no nodes with label
$X^{\bullet}$ for any $X$. Now we shall show that for every adjunction
grammar of this kind there exists a grammar generating the same
set of trees where there is no obligation for adjunction.
We adjoin to a centre tree as often as necessary to
eliminate the obligation. The same we do for adjunction trees.
The resulting trees shall be our new centre and adjunction
trees. Obviously, such trees exist (otherwise we may choose
the set of centre trees to be empty). Now we have to show that
there exists a finite set of minimal trees. Look at a tree
without adjunction obligation and take a node. This node
has a history. It has been obtained by successive adjunction.
If this sequence contains an adjunction tree twice, we may
cut the cycle. (The details of this operation are left to the
reader.) This grammar still generates the same trees. So,
we may remain with the standard form of TAGs.

Now we shall first prove that adjunction grammars cannot generate
more languages as linear 2--LMGs. From this it immediately follows
that they can be parsed in polynomial time. The following is from 
\shortcite{shanker-weir-joshi:coling86}, who incidentally show the 
converse of that theorem as well: head grammars are weakly 
equivalent to TAGs.
%%
\begin{thm}[Vijay--Shanker \& Weir \& Joshi]
%%%
\index{Vijay--Shanker, K.}%%%
\index{Weir, David}%%%
\index{Joshi, Aravind}%%%
%%%
For every TAG $G$ there exists a head grammar $K$ such that $L(K) = L(G)$.
\end{thm}
%%
\proofbeg 
Let $G$ be given. We assume that the trees have pairwise
disjoint sets of nodes. We may also assume that the trees are at
most binary branching. (We only need to show weak equivalence.)
Furthermore, we can assume that the nodes are strictly branching
if not preterminal. The set of all nodes is denoted by $M$. The
alphabet of nonterminals is $N' := \{i^a : i \in M\} \cup \{i^n :
i \in M\}$. The start symbol is the set of all $i^a$ and $i^n$
where $i$ is the root of a centre tree. By massaging the grammar
somewhat one can achieve that the grammar contains only one start
symbol. Now we shall define the rules. For a local tree we put
%%
\begin{equation}
\label{eq:rulet}
i(a,\varepsilon) \hrn  .
\end{equation}
%%
if $i$ is a leaf with terminal symbol $a$. If $i$ is a
distinguished leaf of an adjunction tree we also take
the rule
%%
\begin{equation}
\label{eq:rulee}
i^n(\varepsilon,\varepsilon) \hrn .
\end{equation}
%%
Now let $i \pf j\quad k$ be a branching local tree.
Then we add the following rules.
%%
\begin{equation}
\label{eq:rulep}
i^a(x_0x_1, y_0y_1) \hrn j^n(x_0,x_1), k^n(y_0,y_1).
\end{equation}
%%
Further, if $i$  is a node to which a tree with root $j$ can 
be adjoined, then also this is a rule.
%%
\begin{equation}
\label{eq:rulef}
i^n(x_0y_0, y_1x_1) \hrn j^n(x_0,x_1)\quad i^a(y_0,y_1). 
\end{equation}
%%
If adjunction is not necessary or prohibited at $i$, then
finally the following rule is added.
%%
\begin{equation}
\label{eq:rulen}
i^n(x_0, x_1) \hrn i^a(x_0,x_1).
\end{equation}
%%
This ends the definition of $K$. In view of the rules
\eqref{eq:rulep} it is not entirely clear that we are dealing with a
head grammar. So, replace the rules \eqref{eq:rulep} by the following
rules:
%%
\begin{align}
i^a(x_0, x_1y_0y_1) & \hrn j^{n\bullet}(x_0,x_1), k^{n\bullet}(y_0,y_1).
\\
j^{n\bullet}(x_0x_1y_0,y_1) & \hrn j^n(x_0,x_1), \mbox{\tt L}(y_0,y_1).
\\
k^{n\bullet}(x_0, x_1y_0y_1) & \hrn \mbox{\tt L}(x_0, x_1),
    k^n(y_0,y_1). \\
\mbox{\tt L}(\varepsilon, \varepsilon) & \hrn .
\end{align}
%%
These are rules of a head grammar; \eqref{eq:rulep} can be derived 
from them. For this reason we remain with the rules \eqref{eq:rulep}.

It remains to show that $L(K) = L(G)$. First the inclusion
$L(G) \subseteq L(K)$. We show the following. Let $\GT$ be a local
tree which contains exactly one distinguished leaf and
nonterminal leaves $x_i$, $i < n$, with labels $k_i$. Let therefore
$j < i$ be distinguished. We associate with $\GT$ a vector
polynomial $\Gp(\GT)$ which returns
%%
\begin{equation}
\auf \prod_{i < j} \vec{y}_i\vec{z}_i,
\prod_{j < i < n} \vec{y}_i\vec{z}_i\zu
\end{equation}
%%
for given pairs of strings $\auf \vec{y}_i, \vec{z}_i\zu$.
It is possible to show by induction over $\GT$ that there is a
$K$--derivation
%%
\begin{multline}
i^n(\Gp(\GT)(\auf \auf \vec{y}_i, \vec{z}_i\zu : i < n\zu))
\hrn^{\ast} k_0^n(\auf \vec{y}_0, \vec{z}_0\zu), \\
\dotsc, 
k_{n-1}^n(\auf \vec{y}_{n-1}, \vec{z}_{n-1}\zu).
\end{multline}
%%
If no leaf is distinguished in $\GT$ the value of $p(\GT)$ is
exactly
%%
\begin{equation}
\auf \vec{y}_0\vec{z}_0,
\prod_{0 < i < n} \vec{y}_i\vec{z}_i\zu 
\end{equation}
%%
This claim can be proved inductively over the derivation of
$\GT$ in $G$. From this it follows immediately that $\vec{x}
\in L(K)$ if $\vec{x} \in L(G)$. For the converse inclusion one
has to choose a different proof. Let $\vec{x} \in L(K)$.
We choose a $K$--derivation of $\vec{x}$. Assume that no rule of
type \eqref{eq:rulef} has been used. Then $\vec{x}$ is the string of a
centre tree as is easily seen. Now we assume that the claim
has been shown for derivations with fewer than $n$ applications
of \eqref{eq:rulef} and that the proof has exactly $n$ applications.
We look at the last application. This is followed only by
applications of \eqref{eq:rulep}, \eqref{eq:rulet} and 
\eqref{eq:rulee}. These commute if they belong to different 
subtrees. We can therefore rearrange the order such that our 
application of \eqref{eq:rulef} is followed exactly by those 
applications of \eqref{eq:rulep}, \eqref{eq:rulet} and 
\eqref{eq:rulee} which belong to that subtree. They derive
%%
\begin{equation}
i^a(\vec{x}_0, \vec{x}_1).
\end{equation}
%%
where $i$ is the left hand side of the application of \eqref{eq:rulef}, 
and $\auf \vec{x}_0, \vec{x}_1\zu$ is the pair of the adjunction
tree whose root is $i$. ($\vec{x}_0$ is to the left of the
distinguished leaf, $\vec{x}_1$ to the right.)
Before that we have the application of our rule \eqref{eq:rulef}:
%%
\begin{equation}
j^a(\vec{x}_0\vec{y}_0,\vec{y}_1\vec{x}_1) \hrn
i^a(\vec{x}_0, \vec{x}_1), j^n(\vec{y}_0,\vec{y}_1).
\end{equation}
%%
Now we eliminate this part of the derivation. This means that in place
of $j^a(\vec{x}_0\vec{y}_0, \vec{y}_1\vec{x}_1)$ we only have
$j^n(\vec{y}_0, \vec{y}_1)$. This however is derivable (we
already have the derivation). But on the side of the adjunction
this corresponds exactly to the disembedding of the corresponding
adjunction tree.
%%
\proofend

The converse also holds. However, the head grammars do not exhaust 
the 2--LMGs. For example look at the following grammar $G$.
%%
\begin{align}
\notag
\mbox{\tt S}(y_0x_0y_1,x_1) & \hrn \mbox{\tt T}(x_0,x_1),
    \mbox{\tt H}(y_0,y_1). \\
\notag
\mbox{\tt T}(x_0, \mbox{\tt c}x_1\mbox{\tt d}) & \hrn
    \mbox{\tt U}(x_0,y_1). \\
\notag
\mbox{\tt U}(\mbox{\tt a}x_0\mbox{\tt b}, x_1) & \hrn
    \mbox{\tt S}(x_0,x_1). \\
\mbox{\tt S}(\mbox{\tt ab}, \mbox{\tt cd}) & \hrn . \\
\notag
\mbox{\tt H}(\mbox{\tt t}x_0\mbox{\tt u}, x_1) & \hrn
    \mbox{\tt K}(x_0, x_1). \\
\notag
\mbox{\tt K}(x_0, \mbox{\tt v}x_1\mbox{\tt w}) & \hrn
    \mbox{\tt H}(x_0,x_1). \\
\notag
\mbox{\tt H}(\varepsilon, \varepsilon) & \hrn.
\end{align}
%%
To analyze the generated language we remark the following facts.
%%
\begin{lem}
$\mbox{\tt H}(\vec{x}, \vec{y})$ iff
$\auf \vec{x}, \vec{y}\zu = \auf \mbox{\tt t}^n\mbox{\tt u}^n,
\mbox{\tt v}^n\mbox{\tt w}^n\zu$ for some $n \in \omega$.
\end{lem}
%%
As a proof one may reflect that first of all $\vdash_G
\mbox{\tt H}(\varepsilon, \varepsilon)$ and secondly
%%
\begin{equation}
\vdash_G \mbox{\tt H}(\mbox{\tt t}x_0\mbox{\tt u},
    \mbox{\tt v}x_1\mbox{\tt w}) \mbox{ iff }
    \vdash_G \mbox{\tt H}(x_0, x_1)
\end{equation}
%%
From this the following characterization can be derived.
%%
\begin{lem}
Let $\vec{x}_n := \mbox{\tt t}^n\mbox{\tt u}^n$ and
$\vec{y}_n := \mbox{\tt v}^n\mbox{\tt w}^n$. Then
%%
\begin{multline}
L(G) = \{\mbox{\tt a}\vec{x}_{n_0}\mbox{\tt a}\vec{x}_{n_1}
    \mbox{\tt a}\dotsb\vec{x}_{n_{k-1}}\mbox{\tt ab}
    \vec{y}_{n_{k-1}}\mbox{\tt b}\dotsb\mbox{\tt b}
    \vec{y}_{n_1}\mbox{\tt b}\vec{y}_{n_0}\mbox{\tt bc}^k
    \mbox{\tt d}^k : \\
k \in \omega, n_i \in \omega \text{ for all }i < k\}
\end{multline}
%%
In particular, for every $\vec{x} \in L(G)$
%%
\begin{equation}
\mu(\vec{x}) = m(\mbox{\tt a} + \mbox{\tt b} + \mbox{\tt c}
      + \mbox{\tt d}) + n(\mbox{\tt t} + \mbox{\tt u} +
        \mbox{\tt v} + \mbox{\tt w})
\end{equation}
%%
for certain natural numbers $m$ and $n$.
\end{lem}
%%
For example
%%
\begin{center}
{\tt aabbccdd}, {\tt atuabvwbccdd}, {\tt attuuatuabbvwbvvwwbcccddd},
$\dotsc$
\end{center}
%%
are in $L(G)$ but not
%%
\begin{center}
{\tt atuabbcd}, {\tt attuuatuabvwbvvwwbccdd}
\end{center}
%%
Now for the promised proof that there is no TAG which can
generate this language. 
%%
\begin{lem}
Let $H$ be a TAG with $L(H) = L(G)$ and $\GB$ a centre or
adjunction tree. Then
%%
\begin{equation}
\mu(\GB) = m_{\GB}(\mbox{\tt a} + \mbox{\tt b} + \mbox{\tt c}
    + \mbox{\tt d}) + n_{\GB}(\mbox{\tt t} + \mbox{\tt u} +
        \mbox{\tt v} + \mbox{\tt w})
\end{equation}
%%
for certain natural numbers $m_{\GB}$ and $n_{\GB}$.
%%
\end{lem}
%%
We put $\rho_{\GB} := n_{\GB}/m_{\GB}$. (This is $\infty$,
if $m = 0$.) Certainly, there exists the minimum of all
$\rho_{\GB}$ for all adjunction trees. It is easy to show that
it must be $0$. So there exists an adjunction tree
which consists only of {\tt t}, {\tt u}, {\tt v} and {\tt w},
in equal number. Further  there exists an adjunction tree
which contains {\tt a}.

Let $\vec{x}$ be a string from $L(G)$ such that
%%
\begin{equation}
\mu(\vec{x}) = m(\mbox{\tt a} + \mbox{\tt b} + \mbox{\tt c}
    + \mbox{\tt d}) + n(\mbox{\tt t} + \mbox{\tt u} +
        \mbox{\tt v} + \mbox{\tt w})
\end{equation}
%%
for certain natural numbers $m$ and $n$ such that
(a) $m$ is larger than any $m_{\GB}$, and
(b) $n/m$ is smaller than any $\rho_{\GB}$ that is not equal to 0.
It is to be noticed that such a $\vec{x}$ exists.
If $m$ and $n$ are chosen, the following string does the
job.
%%
\begin{equation}
\label{eq:55insert}
\mbox{\tt a}\mbox{\tt t}^n\mbox{\tt u}^n\mbox{\tt a}^{m-1}
\mbox{\tt b}^{n-1}\mbox{\tt v}^n\mbox{\tt w}^n\mbox{\tt bc}^m
\mbox{\tt d}^m
\end{equation}
%%
This string results from a centre tree by adjoining  (a$'$) an
$\GA$ in which {\tt a} occurs, by adjoining (b$'$) a $\GB$
in which {\tt a} does not occur. Now we look at points in which
$\GB$ has been inserted in \eqref{eq:55insert}. These can only 
be as follows.
%%
\begin{equation}
\mbox{\tt a}\mbox{\tt t}^n\bullet\mbox{\tt u}^n\mbox{\tt a}^{m-1}
\mbox{\tt b}^{n-1}\mbox{\tt v}^n\bullet\mbox{\tt w}^n\mbox{\tt bc}^m
\mbox{\tt d}^m
\end{equation}
%%
However, let us look where the adjunction tree $\GA$ has been
inserted.
%%
\begin{equation}
\mbox{\tt a}\mbox{\tt t}^n\mbox{\tt u}^n\mbox{\tt a}^{m-1}
\circ \mbox{\tt b}^{n-1}\mbox{\tt v}^n\mbox{\tt w}^n\mbox{\tt bc}^m
\circ\mbox{\tt d}^m
\end{equation}
%%
If we put this on top of each other, we get 
%%
\begin{equation}
\mbox{\tt a}\mbox{\tt t}^n\bullet\mbox{\tt u}^n\mbox{\tt a}^{m-1}
\circ \mbox{\tt b}^{n-1}\mbox{\tt v}^n\mbox{\tt w}^n\bullet
\mbox{\tt bc}^m \circ\mbox{\tt d}^m
\end{equation}
%%
Now we have a contradiction. The points of adjunction may not
cross! For the subword between the two $\bullet$ must be a
constituent, likewise the part between the two $\circ$. However,
these constituents are not contained in each other. (In order
for this to become a real proof one has to reflect over the fact
that the constituent structure is not changed by adjunction.
This is Exercise~\ref{ex:tagstruct}.)

So we have a 2--LMG which generates a language that cannot be
generated by a TAG. This grammar is 2--branching. In turn, 
2--branching 2--LMGs are weaker than full linear 2--LMGs. 
Some parts of the argumentation shall be transferred
to the exercises, since they are not of central concern.
%%
\begin{defn}
%%%
\index{literal movement grammar!$n$--branching}%%%
%%%
A linear LMG is called $n$--\textbf{branching} if the polynomial
base consists of at most $k$--ary vector polynomials.
\end{defn}
%%
The reason for this definition is the following fact.
%%
\begin{prop}
\label{prop:nverzweig}
Let $L = L(G)$ for some $n$--branching, $k$--linear
LMG $G$. Then there exists a $k$--linear LMG $H$ with $L(H) = L$
in which every rule is at most $n$--branching.
\end{prop}
%%
To this end one has to see that a rule with more than $n$ daughters
can be replaced by a canonical sequence of rules with at most
$n$ daughters, if the corresponding vector polynomial is generated
by at most $n$--ary polynomials. On the other hand it is not
guaranteed that there is no $n$--branching grammar if higher
polynomials have been used. Additionally, it is possible to construct
languages such that essentially $n+1$--ary polynomials have been
used and they cannot be reduced to at most $n$--ary polynomials.
Define as before
%%
\begin{align}
\vec{x}_n & := \mbox{\tt t}^n\mbox{\tt u}^n &
\vec{y}_n & := \mbox{\tt v}^n\mbox{\tt w}^n
\end{align}
%%
The following polynomial is not generable using polynomials that
are at most ternary.
%%
\begin{equation}
\Gq(\auf w_0,w_1\zu,\auf x_0,x_1 \zu, \auf y_0,y_1\zu,
\auf z_0z_1\zu) 
:= \auf w_0x_0y_0z_0, y_1w_1z_1x_1\zu
\end{equation}
%%
From this we can produce a proof that the following language
cannot be generated by a 2--branching LMG.
%%
\begin{equation}
L = \{\vec{x}_{n_0}\vec{x}_{n_1}\vec{x}_{n_2}\vec{x}_{n_3}%
\vec{y}_{n_2}\vec{y}_{n_0}\vec{y}_{n_3}\vec{y}_{n_1} :
n_0, n_1, n_2, n_3 \in \omega\}
\end{equation}

We close this section with a few remarks on the semantics. Adjunction 
is an operation that takes complete trees as input and returns a 
complete tree. This concept is not easily coupled with a semantics 
that assembles the meanings of sentences from their parts. It is 
--- at least in Montague semantics --- impossible to recover the 
meaning components of a sentence after completion, which would be 
necessary for a compositional account.  \cite{harris:structures} 
%%%
\index{Harris, Zellig S.}%%%
%%%
only gives a modest sketch of how adjunction 
is done in semantics. Principally, for this to work one needs a full 
record of which items are correlated to which parts of meaning 
(which is assumed, for example, in many syntactic theories, for 
example LFG and HPSG).
%%
\vplatz
\exercise
\label{ex:tagstruct}
Let $\GB$ be a tree and $\GA$ an adjunction tree. Let $\GC$
be the result of adjoining $\GA$ to $x$ in $\GB$. We view
$\GB$ in a natural way as a subtree of $\GC$ with $x$
the lower node of $\GA$ in $\GC$. Show the following: the
constituents of $\GB$ are exactly the intersection of constituents
of $\GC$ with the set of nodes of $\GB$.
%
\vplatz
\exercise
Show that the language $L := \{\mbox{\tt a}^n\mbox{\tt b}^n%
\mbox{\tt c}^n\mbox{\tt d}^n : n \in \omega\}$  cannot be
generated by an unregulated TAG. {\it Hint.} Proceed as in the
proof above.  Take a string which is large enough so that a tree
has been adjoined and analyze the places where it has been
adjoined.
%%
\vplatz
\exercise
Show that in the example above $\min \{\rho_{\GB} : \GB \in \BA\} = 0$. 
{\it Hint.} Compare the discussion in Section~\ref{kap2}.\ref{kap2-6}.
%%
\vplatz
\exercise
Show the following: {\it For every TAG $G$ there is a
TAG $G^{\diamondsuit}$ in standard form such that
$G^{\diamondsuit}$ and $G$ have the same constituent structures.}
What can you say about the labelling function?
%%
\vplatz
\exercise
Prove Proposition~\ref{prop:nverzweig}.
%%
