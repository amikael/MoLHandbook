\section{Pentus' Theorem}
%
%
%
It was conjectured by Noam Chomsky that the languages generated by 
$\mathsf{L}$ are context free, which means that $\mathsf{L}$ is in effect 
not stronger than $\mathsf{AB}$. This was first shown by Mati Pentus 
%%%
\index{Pentus, Mati}%%
%%%
(see \cite{pentus:lambek}). His proof makes use of the fact that 
$\mathsf{L}$ has interpolation. We start with a simple observation. 
Let $\GG := \auf G, \cdot, ^{-1}, 1\zu$ be a group and 
$\gamma \colon C \pf G$. We extend $\gamma$ 
to all types and structures as follows.
%%
\begin{equation}
\begin{split}
\gamma(\alpha \bullet \beta) & := \gamma(\alpha) \cdot \gamma(\beta) \\
\gamma(\alpha / \beta) & := \gamma(\alpha) \cdot \gamma(\beta)^{-1} \\
\gamma(\beta \backslash \alpha) & := \gamma(\beta)^{-1} \cdot
        \gamma(\alpha) \\
\gamma(\Gamma \circ \Delta) & := \gamma(\Gamma) \cdot \gamma(\Delta)
\end{split}
\end{equation}
%%
We call $\gamma$ a \textbf{group valued interpretation}.
%%%
\index{interpretation!group valued}%%
%%%
%%
\begin{thm}[Roorda]
%%%%
\index{Roorda, Dirk}%%
%%%
\label{gruppenwertig}
If $\Gamma \bvdash \alpha$ is derivable in $\mathsf{L}$ then for all 
group valued interpretations $\gamma$ $\gamma(\Gamma) = \gamma(\alpha)$.
\end{thm}
%%
The proof is performed by induction over the length of the derivation
and is left as an exercise. Let $C$ be given and $c \in C$. For a
category $\alpha$ over $C$ we define
%%
\begin{equation}
\begin{split}
\sigma_c(c') & := 
    \begin{cases}
    1  & \text{ if $c = c'$,} \\
    0  & \text{ otherwise.}
    \end{cases} \\
\sigma_c(\alpha \bullet \beta) & := \sigma_c(\alpha) + \sigma_c(\beta) \\
\sigma_c(\alpha/\beta) & := \sigma_c(\alpha) + \sigma_c(\beta) \\
\sigma_c(\beta\backslash \alpha) & := \sigma_c(\alpha) + \sigma_c(\beta)
\end{split}
\end{equation}
%%
Likewise we define
%%
\begin{align}
| \alpha | & := \sum_{c \in C} \sigma_c(\alpha) \\
\pi(\alpha) & := \{c \in C : \sigma_c(\alpha) > 0\}
\end{align}
%%
These definitions are extended in the canonical way to
structures. Let $\Delta$ be a nonempty structure (that is, $\Delta \neq
\varepsilon$) and $\Gamma[-]$ a structure containing a marked
occurrence of a substructure. An \textbf{interpolant} %%%
%%%
\index{interpolant}%%
%%%
for a sequent $\Gamma[\Delta] \bvdash \alpha$ in a calculus
%%
$\CS$ with respect to  $\Delta$ is a category $\theta$ such that
%%
\begin{dingautolist}{192}
\item $\sigma_c(\theta) \leq \min \{\sigma_c(\Gamma) +
        \sigma_c(\alpha),\sigma_c(\Delta)\}$, for all $c \in C$,
\item $\Delta \bvdash \theta$ is derivable in $\CS$,
\item $\Gamma[\theta] \bvdash \alpha$ is derivable in $\CS$.
\end{dingautolist}
%%
In particular $\pi(\theta) \subseteq \pi(\Gamma \circ \alpha) \cap 
\pi(\Delta)$ if $\theta$ satisfies these conditions. We say that 
$\CS$ has \textbf{interpolation} %%%
%%%
\index{interpolation}%%
%%%
if for every derivable $\Gamma[\Delta] \bvdash \alpha$ there
exists an interpolant with respect to $\Delta$.

We are interested in the calculi $\mathsf{AB}$ and $\mathsf{L}$.
In the case of $\mathsf{L}$ we have to remark that in presence
of full associativity the interpolation property can be
formulated as follows. We deal with sequents of the form
$\Gamma \bvdash \alpha$ where $\Gamma$ is a sequence of categories.
If $\Gamma = \Theta_1, \Delta, \Theta_2$ with $\Delta \neq
\varepsilon$ then there is an interpolant with respect to
$\Delta$. For let $\Delta^{\circ}$ be a structure in $\circ$
which corresponds to $\Delta$ (after omitting all occurrences of
$\circ$). Then there exists a sequent $\Gamma^{\circ} \bvdash \alpha$
which is derivable and in which $\Delta^{\circ}$ occurs as a
substructure.

Interpolation is shown by induction on the derivation. In the case 
of an axiom there is nothing to show.
For there we have a sequent $\alpha \bvdash \alpha$ and the marked
structure $\Delta$ has to be $\alpha$. In this case $\alpha$ is
an interpolant. Now let us assume that the rule (\textbf{I}--{\mtt{\tf}}) 
has been applied to yield the final sequent. Further, assume that the
interpolation property has been shown for the premisses.
Then we have the following constellation.
%%
\begin{equation}
\begin{array}{c}
\Gamma[\Delta] \circ \alpha \bvdash \beta \\\hline
\Gamma[\Delta] \bvdash \beta/\alpha
\end{array}
\end{equation}
%%
We have to find an interpolant with respect to $\Delta$.
By induction hypothesis there is a formula $\theta$ such that
$\Gamma[\theta] \circ \alpha \bvdash \beta$ and
$\Delta \bvdash \theta$ are both derivable and
$\sigma_c(\theta) \leq \min\{\sigma_c(\Gamma \circ \alpha \circ \beta), %
\sigma_c(\Delta)\}$ for all $c \in C$. Then also 
$\Gamma[\theta] \bvdash \beta/\alpha$
and $\Delta \bvdash \theta$ are derivable and we have
$\sigma_c(\theta) \leq \min\{\sigma_c(\Gamma \circ
\beta/\alpha), \sigma_c(\Delta)\}$. Hence $\theta$ also is an
interpolant with respect to $\Delta$ in $\Gamma[\Delta] \bvdash %
\beta/\alpha$. The case of (\textbf{I}--{\mtt{\tb}}) is fully
analogous.

Now we look at the case that the last rule is ({\mtt{\tf}}--\textbf{I}).
%%
\begin{equation}
\begin{array}{c}
\Gamma \bvdash \beta \qquad \Delta[\alpha] \bvdash \gamma \\\hline
\Delta[\alpha/\beta \circ \Gamma] \bvdash \gamma
\end{array}
\end{equation}
%%
Choose a substructure $Z$ from $\Delta[\alpha/\beta \circ \Gamma]$.
Several cases have to be distinguished.
(1) $Z$ is a substructure of $\Gamma$, that is, $\Gamma =
\Gamma'[Z]$. Then there exists an interpolant $\theta$ for
$\Gamma'[Z] \bvdash \beta$ with respect to $Z$. Then
$\theta$ also is an interpolant for $\Delta[\alpha/\beta
\circ \Gamma'[Z]] \bvdash \gamma$ with respect to $Z$.
(2) $Z$ is disjoint with $\alpha/\beta \circ \Gamma$. Then 
we have $\Delta[\alpha] = \Delta'[Z, \alpha]$ (with two marked 
occurrences of structures) and there is an interpolant $\theta$ 
with respect to $Z$ for $\Delta'[Z,\alpha]
\bvdash \gamma$. Also in this case one calculates that
$\theta$ is the desired interpolant. (3) $Z = \alpha/\beta$.
By induction hypothesis there is an interpolant $\theta_{\ell}$
for $\Gamma \bvdash \beta$ with respect to $\Gamma$, as well as
an interpolant $\theta_r$ for $\Delta[\alpha] \bvdash
\gamma$ with respect to $\alpha$. Then $\theta := \theta_r/\theta_{\ell}$
is the interpolant. For we have
%%
\begin{align}
\sigma_c(\theta) & = \sigma_c(\theta_r) + \sigma_c(\theta_{\ell}) \\\notag
                 & \leq 
	\min\{\sigma_c(\Delta \circ \gamma),\sigma_c(\alpha)\} +
\min\{\sigma_c(\beta), \sigma_c(\Gamma)\} \\\notag
                 & \leq 
\min\{\sigma_c(\Delta \circ \Gamma \circ \gamma),
\sigma_c(\alpha/\beta)\}
\end{align}
%%
Furthermore,
%%
\begin{equation}
\begin{array}{c}
\Gamma \bvdash \theta_{\ell} \qquad \Delta[\theta_r] \bvdash \gamma
\\\hline
\Delta[\theta_r/\theta_{\ell} \circ \Gamma] \bvdash \gamma
\end{array}\qquad\qquad
\begin{array}{c}
\theta_{\ell} \bvdash \beta \qquad \alpha \bvdash \theta_r \\\hline
\begin{array}{c}
\alpha/\beta \circ \theta_{\ell} \bvdash \theta_r \\\hline
\alpha/\beta \bvdash \theta_r / \theta_{\ell}
\end{array}
\end{array}
\end{equation}
%%
(4) $Z = \Theta[\alpha/\beta \circ \Gamma]$. Then $\Delta[\alpha/\beta
\circ \Gamma] = \Delta'[\Theta[\alpha/\beta \circ \Gamma]]$ for
some $\Delta'$. Then by hypothesis there is an interpolant for
$\Delta'[\Theta[\alpha]] \bvdash \gamma$ with respect to
$\Theta[\alpha]$. We show that $\theta$ is the desired
interpolant.
%%
\begin{equation}
\begin{array}{c}
\Gamma \bvdash \beta \qquad \Theta[\alpha] \bvdash \theta \\\hline
\Theta[\alpha/\beta \circ \Gamma] \bvdash \theta
\end{array}
\qquad\qquad
\Delta'[\theta] \bvdash \gamma
\end{equation}
%%
In addition 
%%
\begin{align}
\sigma_c(\theta) & \leq  \min\{%
\sigma_c(\Delta' \circ \gamma), \sigma_c(\Theta[\alpha])\} \\\notag
	& \leq  \min\{\sigma_c(\Delta' \circ \gamma),
\sigma_c(\Theta[\alpha/\beta \circ \Gamma])\}
\end{align} 
%%
This ends the proof for the case ({\mtt{\tf}}--\textbf{I}). The case 
({\mtt{\tb}}--\textbf{I}) again is fully analogous.
%%
\begin{thm}
$\mathsf{AB}$ has interpolation.
\proofend
\end{thm}
%%
Now we move on to $\mathsf{L}$. Clearly, we only have to discuss the
new rules. Let us first consider the case where we add $\bullet$ 
together with its introduction rules. Assume that the last rule is 
($\bullet$--\textbf{I}).
%%
\begin{equation}
\begin{array}{c}
\Gamma[\alpha \circ \beta] \bvdash \gamma \\\hline
\Gamma[\alpha \bullet \beta] \bvdash \gamma
\end{array}
\end{equation}
%%
Choose a substructure $Z$ of $\Gamma[\alpha \circ \beta]$.
(1) $Z$ does not contain the marked occurrence of  $\alpha
\bullet \beta$. Then $\Gamma[\alpha \bullet \beta]
= \Gamma'[Z, \alpha \bullet \beta]$, and by induction hypothesis
we get an interpolant $\theta$ for $\Gamma'[Z, \alpha \circ \beta]
\bvdash \gamma$ with respect to $Z$. It is easily checked that
$\theta$ also is an interpolant for $\Gamma'[Z, \alpha \bullet \beta] %
\bvdash \gamma$ with respect to $Z$.
(2) Let $Z = \Theta[\alpha \bullet \beta]$. Then
$\Gamma[\alpha \bullet \beta] = \Gamma'[\Theta[\alpha \bullet
\beta]]$. By induction hypothesis there is an interpolant $\theta$
for $\Gamma'[\Theta[\alpha \circ \beta]] \bvdash \gamma$ with respect
to $\Theta[\alpha \circ \beta]$, and it also is an interpolant for
$\Gamma'[\Theta[\alpha \bullet \beta]] \bvdash \gamma$
with respect to $\Theta[\alpha \bullet \beta]$.
In both cases we have found an interpolant.

Now we turn to the case (\textbf{I}--$\bullet$).
%%
\begin{equation}
\begin{array}{c}
\Gamma \bvdash \alpha \qquad \Delta \bvdash \beta \\\hline
\Gamma \circ \Delta \bvdash \alpha \bullet \beta
\end{array}
\end{equation}
%%
There are now three cases for $Z$. (1) $\Gamma = \Gamma'[Z]$.
By  induction hypothesis there is an interpolant $\theta_{\ell}$
for $\Gamma'[Z] \bvdash \alpha$ with respect to $Z$. This is the
desired interpolant. (2) $\Delta = \Delta'[Z]$. Analogous to (1).
(3) $Z = \Gamma \circ \Delta$. By hypothesis there is an interpolant
$\theta_{\ell}$ for $\Gamma \bvdash \alpha$ with respect to
$\Gamma$ and an interpolant $\theta_r$ for $\Delta
\bvdash \beta$ with respect to $\Delta$. Put $\theta :=
\theta_{\ell} \bullet \theta_r$. This is the desired
interpolant. For
%%
\begin{equation}
\begin{array}{c}
\Gamma \bvdash \theta_{\ell} \qquad \Delta \bvdash \theta_r \\\hline
\Gamma \circ \Delta \bvdash \theta_{\ell} \bullet \theta_r
\end{array}
\qquad \qquad
\begin{array}{c}
\theta_{\ell} \bvdash \alpha \qquad \theta_r \bvdash \beta \\\hline
\begin{array}{c}
\theta_{\ell} \circ \theta_r \bvdash \alpha \bullet \beta \\\hline
\theta_{\ell} \bullet \theta_r \bvdash \alpha \bullet \beta
\end{array}
\end{array}
\end{equation}
%%
In addition it is calculated that
$\sigma_c(\theta) \leq \min\{\sigma_c(\alpha \bullet
\beta), \sigma_c(\Gamma \circ \Delta)\}$.

This concludes a proof of interpolation for $\mathsf{NL}$.
Finally we must study $\mathsf{L}$. The rules (\textbf{ass1}), 
(\textbf{ass2}) pose a technical problem since we cannot 
proceed by induction on the derivation. For the applications 
of these rules change the structure. Hence we change to another 
system of sequents and turn --- as discussed above --- to 
sequents of the form $\Gamma \bvdash \alpha$ where $\Gamma$ is 
a sequence of categories.
In this case the rules (\textbf{ass1}) and (\textbf{ass2}) must be
eliminated. However, in the proof we must make more distinctions
in cases. The rules (\textbf{I}--{\mtt{\tf}}) and (\textbf{I}--{\mtt{\tb}})
are still unproblematic. So we look at a more complicated case,
namely an application of the rule ({\mtt{\tf}}--\textbf{I}).
%%
\begin{equation}
\begin{array}{c}
\Gamma \bvdash \beta \qquad \Delta[\alpha] \bvdash \gamma
\\\hline
\Delta[\alpha/\beta, \Gamma] \bvdash \gamma
\end{array}
\end{equation}
%%
We can segment the structure $\Delta[\alpha/\beta, \Gamma]$
into $\Delta', \alpha/\beta, \Gamma, \Delta''$.
Let a subsequence $Z$ be distinguished in $\Delta', \alpha/\beta, \Gamma,
\Delta''$. The case where $Z$ is fully contained in $\Delta'$
is relatively easy; likewise the case where $Z$ is fully contained
in $\Delta''$. The following cases remain.
(1) $Z = \Delta_1, \alpha/\beta, \Gamma_1$,
where $\Delta' = \Delta_0, \Delta_1$ for some $\Delta_0$,
and $\Gamma = \Gamma_1, \Gamma_2$ for some $\Gamma_2$.
Even if $Z$ is not empty $\Delta_1$ as well as
$\Gamma_1$ may be empty. Assume  $\Gamma_1 \neq \varepsilon$.
In this case $\theta_{\ell}$ an interpolant
for $\Gamma \bvdash \beta$ with respect to $\Gamma_2$ and
$\theta_r$ an interpolant of $\Delta[\alpha] \bvdash \gamma$
with respect to $\Delta_1, \alpha$. (Here it becomes clear why we
need not assume $\Delta_1 \neq \varepsilon$.)
The following sequents are therefore derivable.
%%
\begin{equation}
\begin{array}{r@{}l@{\qquad}r@{}l}
\Gamma_2 & \bvdash \theta_{\ell} & \Gamma_1, \theta_{\ell} & \bvdash \beta \\
\Delta_1, \alpha & \bvdash \theta_r & \Delta_0, \theta_r, \Delta''
    & \bvdash \gamma
\end{array}
\end{equation}
%%
Now put $\theta := \theta_r/\theta_{\ell}$. Then we have
on the one hand
%%
\begin{equation}
\begin{array}{c}
\Delta_1, \alpha \bvdash \theta_r \qquad \Gamma_1, \theta_{\ell} \bvdash
    \beta \\\hline
\Delta_1, \alpha/\beta, \Gamma_1, \theta_{\ell} \bvdash \theta_r
    \\\hline
\Delta_1, \alpha/\beta, \Gamma_1 \bvdash \theta_r/\theta_{\ell}
\end{array}
\end{equation}
%%%%
and on the other 
%%%%
\begin{equation}
\begin{array}{c}
\Gamma_2 \bvdash \theta_{\ell} \qquad \Delta_0, \theta_r,
    \Delta ''\bvdash \gamma \\\hline
\Delta_0, \theta_r/\theta_{\ell}, \Gamma_2, \Delta'' \bvdash
\gamma
\end{array}
\end{equation}
%%
The conditions on the numbers of occurrences of symbols are
easy to check. (2) As Case (1), but $\Gamma_1$ is empty.
Let then $\theta_{\ell}$ be an interpolant for $\Gamma \bvdash
\beta$ with respect to $\Gamma$ and $\theta_r$ an interpolant
for $\Delta_0, \Delta_1, \alpha, \Delta'' \bvdash \gamma$
with respect to $\Delta_1, \alpha$. Then put $\theta := \theta_r/
\theta_{\ell}$. $\theta$ is an interpolant for the end sequent
with respect to $Z$.
%%
\begin{equation}
\begin{array}{c}
\theta_{\ell} \bvdash \beta \qquad \Delta_1, \alpha \bvdash \theta_r
    \\\hline
\Delta_1, \alpha/\beta, \theta_{\ell} \bvdash \theta_r \\\hline
\Delta_1, \alpha/\beta \bvdash \theta_r / \theta_{\ell}
\end{array}
\qquad
\begin{array}{c}
\Gamma \bvdash \theta_{\ell} \qquad \Delta_0, \theta_r, \Delta''
    \bvdash \gamma \\\hline
\Delta_0, \theta_r /\theta_{\ell}, \Gamma, \Delta'' \bvdash
    \gamma
\end{array}
\end{equation}
%%%
(3) $Z$ does not contain the marked occurrence of $\alpha/\beta$.
In this case $Z = \Gamma_2, \Delta_1$ for some final part $\Gamma_2$
of $\Gamma$ and an initial part $\Delta_1$ of $\Delta''$. $\Gamma_2$
as well as  $\Delta_1$ may be assumed to be nonempty, since otherwise
we have a case that has already been discussed. The situation is
therefore as follows with $Z = \Gamma_2, \Delta_1$.
%%
\begin{equation}
\begin{array}{c}
\Gamma_1, \Gamma_2 \bvdash \beta \qquad \Delta', \alpha,
\Delta_1, \Delta_2 \bvdash \gamma \\\hline
\Delta', \alpha/\beta, \Gamma_1, \Gamma_2, \Delta_1,
\Delta_2 \bvdash \gamma
\end{array}
\end{equation}
%%
Let $\theta_{\ell}$ be an interpolant for $\Gamma_1, \Gamma_2 %
\bvdash \beta$ with respect to $\Gamma_2$ and $\theta_r$ an
interpolant for $\Delta', \alpha, \Delta_1, \Delta_2 \bvdash \gamma$
with respect to $\Delta_1$. Then the following are derivable
%%
\begin{equation}
\begin{array}{r@{}l@{\qquad}r@{}l}
\Gamma_2 & \bvdash \theta_{\ell} & \Gamma_1, \theta_{\ell}
    & \bvdash \beta \\
\Delta_1 & \bvdash \theta_r & \Delta', \alpha, \theta_r, \Delta_2
    & \bvdash \gamma
\end{array}
\end{equation}
%%
Now we choose $\theta := \theta_{\ell} \bullet \theta_r$.
Then we have both
%%
\begin{equation}
\begin{array}{c}
\Gamma_2 \bvdash \theta_{\ell} \qquad \Delta_1 \bvdash \theta_r
    \\\hline
\Gamma_2, \Delta_1 \bvdash \theta_{\ell} \bullet \theta_r
\end{array}
\end{equation}
%%%
and
%%%
\begin{equation}
\begin{array}{c}
\Gamma_1, \theta_{\ell} \bvdash \beta \qquad \Delta', \alpha,
    \theta_r, \Delta_2 \bvdash \gamma \\\hline
\Delta', \alpha/\beta, \Gamma_1, \theta_{\ell}, \theta_r,
    \Delta_2 \bvdash \gamma \\\hline
\Delta', \alpha/\beta, \Gamma_1, \theta_{\ell} \bullet
    \theta_r, \Delta_2 \bvdash \gamma
    \end{array}
\end{equation}
%%
In this case as well the conditions on numbers of occurrences are
easily checked. This exhausts all cases. Notice that we have used
$\bullet$ to construct the interpolant.  In the case of the rules
(\textbf{I}--$\bullet$) and ($\bullet$--\textbf{I}) there are no
surprises with respect to $\mathsf{AB}$.
%%
\begin{thm}[Roorda]
%%%
\index{Roorda, Dirk}%%%
%%%
$\mathsf{L}$ has interpolation.
\proofend
\end{thm}
%%
Now we shall move on to show that $\mathsf{L}$ is context
free. To this end we introduce a series of weak calculi of which we
shall show that together they are not weaker than $\mathsf{L}$.
These calculi are called $\mathsf{L}_m$, $m < \omega$. 
%%%
\index{$L_m$}%%%
%%%
The axioms of $\mathsf{L}_m$ are sequents $\Gamma \bvdash \alpha$ such that
the following holds.
%%
\begin{dingautolist}{192}
\item $\Gamma = \beta_1, \beta_2$ or $\Gamma = \beta_1$
for certain categories $\beta_1$ and $\beta_2$.
\item $\Gamma \bvdash \alpha$ is derivable in $\mathsf{L}$.
\item $|\alpha|, |\beta_1|, |\beta_2| < m$.
\end{dingautolist}
%%
(cut) is the only rule of inference. The main work is in the
proof of the following theorem.
%%
\begin{thm}[Pentus]
\label{reduktion1}
\index{Pentus, Mati}%%%
Let $\Gamma = \beta_0,  \beta_1,  \dotsc, \beta_{n-1}$.
$\Gamma \bvdash \alpha$ is derivable in $\mathsf{L}_m$ iff
%%
\begin{dingautolist}{192}
\item
$|\beta_i| < m$ for all $i < m$,
\item
$|\alpha| < m$ and
\item
$\Gamma \bvdash \alpha$ is derivable in $\mathsf{L}$.
\end{dingautolist}
\end{thm}
%%
We shall show first how to get from this fact that $\mathsf{L}$--grammars
are context free. We weaken the calculi still further. The calculus
$\mathsf{L}_m^{\boxminus}$ 
%%%%
\index{$L_m^{\boxminus}$}%%%
%%%
has the axioms of $\mathsf{L}_m$ but
(cut) may be applied only if the left hand premiss is an axiom.
%%
\begin{lem}
\label{reduktion2}
For all sequents $\Gamma \bvdash \alpha$ the following holds:
$\Gamma \bvdash \alpha$ is derivable in $\mathsf{L}_m^{\boxminus}$
iff $\Gamma \bvdash \alpha$ is derivable in $\mathsf{L}_m$.
\end{lem}
%%
The proof is relatively easy and left as an exercise.
%%
\begin{thm}
The languages accepted by $\mathsf{L}$--grammars are context free.
\end{thm}
%%
\proofbeg
Let $\BL = \auf \mbox{\tt S}, C, \zeta, A, \mathsf{L}\zu$ be given. 
Let $m$ be larger than the maximum of all $|\alpha|$, $\alpha
\in \zeta(a)$, $a \in A$. Since $A$ as well as $\zeta(a)$
are finite, $m$ exists. For simplicity we shall assume that
$C = \bigcup \auf \pi(\alpha) : \alpha \in \zeta(a),
a \in A\zu$. Now we put $N := \{\alpha : |\alpha| < m\}$.
$G := \auf \mbox{\tt S}, N, A, R\zu$, where
%%
\begin{align}
\begin{split}
R := & \phantom{\mbox{}\cup\mbox{}}\{\alpha \pf a : a \in \zeta(a)\} \\
     & \cup \{\alpha \pf \beta : \alpha, \beta \in N,
     \stackrel{\mathsf{L}}{\leadsto} \beta \bvdash \alpha\} \\
     & \cup \{\alpha \pf \beta_0 \beta_1 : 
	\alpha, \beta_0, \beta_1 \in N, 
	\stackrel{\mathsf{L}}{\leadsto} 
	\beta_0, \beta_1 \bvdash \alpha\}
\end{split}
\end{align}
%%
Now let $\BL \vdash \vec{x}$, $\vec{x} = x_0 \conc x_1 \conc
\dotsb x_{n-1}$. Then for all $i < n$ there exist 
an $\alpha_i \in \zeta(x_i)$ such that 
$\Gamma \bvdash \mbox{\tt S}$ is derivable 
in $\mathsf{L}$, where $\Gamma := \alpha_0, \alpha_1, \dotsc, \alpha_{n-1}$. 
By Theorem~\ref{reduktion1} and Lemma~\ref{reduktion2} $\Gamma \bvdash
\mbox{\tt S}$ is also derivable in $\mathsf{L}_m^{\boxminus}$. Induction
over the length of the derivation yields that $\vdash_G \alpha_0
\conc \alpha_1 \conc \dotsb \conc \alpha_{n-1}$ and hence also
$\vdash_G \vec{x}$. Now let conversely $\vdash_G \vec{x}$. We
extend the category assignment $\zeta$ to $\zeta^+ \colon A \cup N \pf
\Cat_{\mbox{\smtt{\tb}}, \bullet, \mbox{\smtt{\tf}}}(C)$ by putting
$\zeta^+(\alpha) := \{\alpha\}$ while $\zeta^+ \restriction A =
\zeta$. By induction over the length of the derivation of
$\vec{\alpha}$ one shows that from $\vdash_G \vec{\alpha}$ we get
$\BL \vdash \vec{\alpha}$. 
\proofend

Now on to the proof of Theorem~\ref{reduktion1}.
%%
\begin{defn}
%%%
\index{category!thin}%%
\index{sequent!thin}%%
\index{thin category}%%
%%%
A category $\alpha$ is called \textbf{thin} if $\sigma_c(\alpha)
\leq 1$ for all $c \in C$. A sequent $\Gamma \bvdash \alpha$
is called \textbf{thin} if the following holds.
%%%
\begin{dingautolist}{192}
\item $\Gamma \bvdash \alpha$ is derivable in $\mathsf{L}$.
\item All categories occurring in $\Gamma$ as well as $\alpha$ are
thin.
\item $\sigma_c(\Gamma, \alpha) \leq 2$ for all $c \in C$.
\end{dingautolist}
%%%
\end{defn}
%%
For a thin category $\alpha$ we always have $|\alpha| =
|\pi(\alpha)|$. We remark that for a thin sequent only
$\sigma_c(\Gamma, \alpha) = 0$ or $= 2$ can occur since
$\sigma_c(\Gamma, \alpha)$ always is an even number in
a derivable sequent (see Exercise~\ref{ex:gerade}). 
Let us look at a thin sequent
$\Gamma[\Delta] \bvdash \alpha$ and an interpolant $\theta$
of it with respect to $\Delta$. Then $\sigma_c(\theta) \leq %
\sigma_c(\Delta) \leq 1$. For either $c \not\in \pi(\Delta)$,
and then $c \not\in \pi(\theta)$, whence $\sigma_c(\theta) = 0$.
Or $c \in \pi(\Delta)$; but then $c \in \pi(\Gamma, \alpha)$,
and so by assumption $\sigma_c(\Delta) = 1$.
%%
\begin{equation}
\sigma_c(\Delta, \theta) \leq
\sigma_c(\Delta) + \sigma_c(\theta) \leq \sigma_c(\Gamma[\Delta],
\alpha) + \sigma_c(\theta) \leq 2 + 1
\end{equation}
%%
Now $\sigma_c(\Delta) + \sigma_c(\theta)$ is an even number
hence either $0$ or $2$. Hence $\Delta \bvdash \theta$
also is thin. Likewise it is shown that $\Gamma[\theta] \bvdash \alpha$
is thin.
%%
\begin{lem}
\label{unduenn}
Let $\Gamma, \Theta, \Delta \bvdash \alpha$ be a sequent
and $c, d \in C$ two distinct elementary categories.
Further, let $c \in \pi(\Gamma) \cap \pi(\Delta)$ as well as
$d \in \pi(\Theta) \cap \pi(\alpha)$. Then $\Gamma, \Theta, \Delta \bvdash
\alpha$ is not thin.
\end{lem}
%%
\proofbeg
Let $\GF_G(C)$ be the free group generated by the elementary categories.
The elements of this group are finite products of the form
$c_0^{s_0} \cdot c_2^{s_2} \cdot \dotsb \cdot c_{n-1}^{s_{n-1}}$,
where $c_i \neq c_{i+1}$ for $i < n-1$ and $s_i \in \BZ - \{0\}$.
(If $n = 0$ then the empty product denotes the group unit, 1.)
For if $c_0 = c_1$ the term $c_0^{s_0} \cdot c_1^{s_1}$ can
be shortened to $c_0^{s_0 + s_1}$. Look at the group valued 
interpretation $\gamma$ sending every element of $C$ to itself. 
If the sequent was thin we would have $\gamma(\Gamma) \cdot 
\gamma(\Theta) \cdot \gamma(\Delta) = \gamma(\alpha)$. By 
hypothesis the left hand side is of the form $w \cdot c^{\pm 1} 
\cdot x \cdot d^{\pm 1} \cdot y \cdot c^{\pm 1} \cdot z$ for certain 
products $w, x, y, z$. The right hand side equals $t \cdot d^{\pm 1}
\cdot u$ for certain $t, u$. Furthermore, we know that terms
which stand for $w$, $x$, $y$, $z$ as well as $t$ and $u$ cannot
contain $c$ or $d$ if maximally reduced. But then equality cannot
hold.
\proofend
%%
\begin{lem}
Let $\alpha_0, \alpha_1, \dotsc, \alpha_{n} \bvdash \alpha_{n+1}$ be 
thin, $n > 0$. Then there is a $k$ with $0 < k < n + 1$ and
$\pi(\alpha_k) \subseteq \pi(\alpha_{k-1}) \cup \pi(\alpha_{k+1})$.
\end{lem}
%%
\proofbeg
The proof is by induction on $n$. We start with $n = 1$. Here
the sequent has the form $\alpha_0, \alpha_1 \bvdash \alpha_2$. Let
$c \in \pi(\alpha_1)$. Then $\sigma_c(\alpha_1) = 1$ since the
sequent is thin. And since $\sigma_c(\alpha_0, \alpha_1, \alpha_2) = 2$,
we have $\sigma_c(\alpha_0, \alpha_2) = 1$, whence
$c \in \pi(\alpha_0) \cup \pi(\alpha_2)$. This finishes the case
$n = 1$. Now let $n > 1$ and the claim proved for all $m < n$. 
\textbf{Case a.} $\pi(\alpha_0, \alpha_1, \dotsc, %
\alpha_{n-2}) \cap \pi(\alpha_{n}) = \varnothing$. Then we choose
$k := n$. For if $c \in \pi(\alpha_{n})$ then $\sigma_c(\alpha_0,
\dotsc, \alpha_{n-2}) = 0$, and so we have $\sigma_c(\alpha_{n-1})
+ \sigma_c(\alpha_{n+1}) = 1$. Hence we get $c \in \pi(\alpha_{n-1})
\cup \pi(\alpha_{n+1})$. \textbf{Case b.} $\pi(\alpha_0,
\alpha_1, \dotsc, \alpha_{n-2}) \cap \pi(\alpha_{n})
\neq \varnothing$. Then there exists an elementary category $c$ with
$c \in \pi(\alpha_0, \dotsc, \alpha_{n-2})$ and
$c \in \pi(\alpha_{n})$. Put $\Gamma := \alpha_0,
\alpha_1, \dotsc, \alpha_{n-1}$, $\Delta := \alpha_{n}$.
Let $\theta$ be an interpolant for $\Gamma, \Delta
\bvdash \alpha_{n+1}$ with respect to $\Gamma$. Then $\Gamma \bvdash
\theta$ and $\theta, \alpha_n \bvdash \alpha_{n+1}$ are thin.
By induction hypothesis there exists a $k$ such that
$\pi(\alpha_k) \subseteq \pi(\alpha_{k-1}) \cup \pi(\alpha_{k+1})$,
if $k < n - 1$, or $\pi(\alpha_k) \subseteq
\pi(\alpha_{k-1}) \cup \pi(\theta)$ in case $k = n-1$. If
$k < n-1$ then $k$ is the desired number for the main sequent.
Let now $k = n-1$. Then 
%%%
\begin{equation}
\pi(\alpha_{n-1}) \subseteq \pi(\alpha_{n-2}) \cup \pi(\theta) 
\subseteq \pi(\alpha_{n-2}) \cup \pi(\alpha_{n}) \cup \pi(\alpha_{n+1})
\end{equation}
%%%
We show that $k$ in this case too is the desired number for the main 
sequent. Let $\pi(\alpha_{n-1}) \cap \pi(\alpha_{n+1}) \neq \varnothing$,
say $d \in \pi(\alpha_{n-1}) \cap \pi(\alpha_{n+1})$. Then surely
$d \not\in \pi(\alpha_{n})$, so $d \neq c$. Therefore the sequent
is not thin, by Lemma~\ref{unduenn}. Hence we have
$\pi(\alpha_{n-1}) \cap \pi(\alpha_{n+1}) = \varnothing$, and so
$\pi(\alpha_{n-1}) \subseteq \pi(\alpha_{n-2}) \cup \pi(\alpha_{n})$.
\proofend
%%
\begin{lem}
\label{duennableitbar}
Let $\Gamma \bvdash \gamma$ be an $\mathsf{L}$--derivable thin sequent 
in which all categories have length $< m$. Then $\Gamma \bvdash \gamma$ 
is already derivable in $\mathsf{L}_m$.
\end{lem}
%%
\proofbeg
Let $\Gamma = \alpha_0, \alpha_1, \dotsc, \alpha_{n-1}$;
put $\alpha_n := \gamma$. If $n \leq 2$ then $\Gamma \bvdash \gamma$
already is an axiom of $\mathsf{L}_m$. So, let $n > 2$. By the
previous lemma there is a $k$ such that 
$\pi(\alpha_k) \subseteq \pi(\alpha_{k-1})
\cup \pi(\alpha_{k+1})$. \textbf{Case 1.} $k < n$. \textbf{Case 1a.}
$| \pi(\alpha_{k-1}) \cap \pi(\alpha_k)| \geq |\pi(\alpha_{k+1}) \cap
\pi(\alpha_k)|$. Put $\Xi := \alpha_0, \alpha_1, \dotsc,
\alpha_{k-2}$, $\Theta := \alpha_{k+1}, \dotsc, \alpha_{n-1}$, 
and $\Delta := \alpha_{k-1}, \alpha_k$. Let
$\theta$ be an interpolant for $\Xi, \Delta, \Theta
\bvdash \alpha_n$ with respect to $\Delta$. Then the sequent
%%
\begin{equation}
\alpha_0, \dotsc, \alpha_{k-2}, \theta,
\alpha_{k+1}, \dotsc, \alpha_{n-1} \bvdash \alpha_n
\end{equation}
%%
is thin. Furthermore
%%
\begin{align}
\pi(\theta) \subseteq & (\pi(\alpha_{k-1}) \cup \pi(\alpha_k))
\cap \pi(\Xi, \Theta, \alpha_n)  \\\notag
        = & 
(\pi(\alpha_{k-1}) \cap \pi(\Xi, \Theta, \alpha_n)) 
\cup (\pi(\alpha_k) \cap \pi(\Xi, \Theta, \alpha_n)).
\end{align}
%%
Let $c \in \pi(\alpha_{k-1})$. Then $\sigma_c(\alpha_{k-1}) = 1$
and $\sigma_c(\Xi, \alpha_{k-1}, \alpha_k, \Theta,
\alpha_n) = 2$, from which $\sigma_c(\Xi, \alpha_k, \Theta,
\alpha_n) = 1$. Hence either $\sigma_c(\alpha_k) = 1$ or
$\sigma_c(\Xi, \Theta, \alpha_n) = 1$. Since $c$ was arbitrary
we have 
%%%
\begin{equation}
\pi(\alpha_k) \cap \pi(\Xi, \Theta, \alpha_n) =
\pi(\alpha_{k-1}) - (\pi(\alpha_{k-1}) \cap \pi(\alpha_k))
\end{equation}
%%%
By choice of $k$, $\pi(\alpha_k) \cap \pi(\Xi, \Theta,
\alpha_n) = \pi(\alpha_k) \cap \pi(\alpha_{k+1})$. Hence 
%%
\begin{equation}
\begin{array}{l@{}l@{}l}
\pi(\theta) & = & 
(\pi(\alpha_{k-1}) \cap \pi(\Xi, \Theta, \alpha_n)) 
(\pi(\alpha_k) \cap \pi(\Xi, \Theta, \alpha_n)) \\
        & \subseteq &
(\pi(\alpha_k) - (\pi(\alpha_{k-1}) \cap \pi(\alpha_k)) 
   \cup (\pi(\alpha_k) \cap \pi(\alpha_{k+1})).
\end{array}
\end{equation}
%%
So
%%
\begin{align}
\begin{split}
|\pi(\theta)| & = |\pi(\alpha_{k-1})| + |\pi(\alpha_{k-1}) \cap
\pi(\alpha_k)| + |\pi(\alpha_k) \cap \pi(\alpha_{k+1})| \\
          & \leq 
|\pi(\alpha_{k-1})| \\
          & <  m
\end{split}
         \end{align} 
%%
(Note that $|\pi(\alpha_{k-1})| = |\alpha_k|$.)
Therefore also $|\theta| < m$ and so $\alpha_{k-1},
\alpha_k \bvdash \theta$ is an axiom of $\mathsf{L}_m$. Hence, 
by induction hypothesis $\Xi, \theta, \Theta \bvdash \alpha_n$
is derivable in $\mathsf{L}_m$. A single application from
both sequents yields the main sequent.  It is therefore derivable
in $\mathsf{L}_m$. \textbf{Case 1b.} $|\pi(\alpha_{k-1}) \cap %
\pi(\alpha_k)| < |\pi(\alpha_k) \cap \pi(\alpha_{l+1})|$. Here
one puts $\Xi := \alpha_0, \dotsc, \alpha_{k-1}$, $\Delta := %
\alpha_k, \alpha_{k+1}$, $\Theta := \alpha_{k+1}, \dotsc, %
\alpha_{n-1}$ and proceeds as in Case 1a. \textbf{Case 2.} $k = n-1$.
So, $\pi(\alpha_{n-1}) \subseteq \pi(\alpha_{n-2}) \cup
\pi(\gamma)$. Also here we distinguish to cases.
\textbf{Case~2a.} $|\pi(\alpha_{n-2}) \cap \pi(\alpha_{n-1})|
\geq |\pi(\alpha_{n-1}) \cap \pi(\alpha_n)|$. This case is similar
to Case 1a. \textbf{Case 2b.} $|\pi(\alpha_{n-2})
\cap \pi(\alpha_{n-1})| < |\pi(\alpha_{n-1}) \cap \pi(\alpha_n)|$.
Here put $\Delta := \alpha_0, \dotsc, \alpha_{n-2}$,
$\Theta := \alpha_{n-1}$. Let $\theta$ be an interpolant for
$\Delta, \Theta \bvdash \alpha_n$ with respect to $\Delta$.
Then $\Delta \bvdash \theta$ as well as $\theta, \alpha_{n-1}
\bvdash \alpha_n$ are thin. Further we have
%%
\begin{align}
\begin{split}
\pi(\theta) \subseteq & \pi(\Delta) \cap (\pi(\alpha_{n-1}) \cup
\pi(\alpha_n)) \\
	 = & (\pi(\Delta) \cap \pi(\alpha_{n-1})) \cup
(\pi(\Delta) \cap \pi(\alpha_n))  \\
        = & 
	(\pi(\alpha_{n-2}) \cap \pi(\alpha_{n-1})) 
	\cup
        (\pi(\alpha_n) - (\pi(\alpha_{n-1}) \cap \pi(\alpha_n))).
\end{split}
\end{align}
%%
As in Case 1a we conclude that
%%
\begin{align}
\begin{split}
|\pi(\theta)| & = 
    |\pi(\alpha_{n-2}) \cap \pi(\alpha_{n-1})| +
    |\pi(\alpha_n)| - |\pi(\alpha_{n-1}) \cap \pi(\alpha_n)| \\
          & < 
    |\pi(\alpha_n)| \\
          & < m
	\end{split}
\end{align}
%%
Hence $\theta, \alpha_{n-1} \bvdash \alpha_n$ is an axiom of
$\mathsf{L}_m$. By induction hypothesis, $\Delta \bvdash \theta$ 
is derivable in $\mathsf{L}_m$. A single application of (cut) yields 
the main sequent, which is therefore derivable in $\mathsf{L}_m$.
\proofend
%%

\noindent
Finally we proceed to the proof of Theorem~\ref{reduktion1}. Let
$|\gamma_i| < m$ for all $i < n$, and $|\alpha| < m$. Finally, let
$\gamma_0, \gamma_1, \dotsc, \gamma_{m-1} \bvdash \alpha$ be
derivable in $\mathsf{L}$. We choose a derivation of this sequent.
We may assume here that the axioms are only sequents of the
form $c \bvdash c$. For every occurrence of an axiom $c \bvdash c$
we choose a new elementary category $\wht{c}$ and replace this
occurrence of $c \bvdash c$ by $\wht{c} \bvdash \wht{c}$. We extend
this to the entire derivation and so we get a new derivation
of a sequent $\wht{\gamma}_0, \wht{\gamma}_1,
\dotsc, \wht{\gamma}_{n-1} \bvdash \wht{\alpha}$. We get
$\sigma_c(\wht{\alpha}) + \sum_{i < n} \sigma_c(\wht{\gamma_i}) = 2$,
if $c$ occurs at all in the sequent. Nevertheless, the sequent
need not be thin, since it may contain categories which are not
thin. However, if $\sigma_c(\delta) = 2$ for some $\delta$ and
some $c$, then $c$ is not contained in any other category.
We exploit this as follows. By successively applying interpolation
we get the following sequents, which are all derivable in $\mathsf{L}$.
%%
\begin{equation}
\begin{array}{r@{}l@{\qquad}r@{}l}
\wht{\gamma}_0 & \bvdash \theta_0 & \theta_0, \wht{\gamma}_1,
    \wht{\gamma}_2, \dotsc, \wht{\gamma}_{n-1}
    & \bvdash \wht{\alpha} \\
\wht{\gamma}_1 & \bvdash \theta_1 & \theta_0, \theta_1,
    \wht{\gamma}_2, \dotsc, \wht{\gamma}_{n-1}
    & \bvdash \wht{\alpha} \\
\vdots\qquad & \qquad \vdots \\
\wht{\gamma}_{n-1} & \bvdash \theta_{n-1} & \theta_0, \theta_1,
    \dotsc, \theta_{n-1} & \bvdash \wht{\alpha} \\
\theta_0, \theta_1, \dotsc, \theta_{n-1} & \bvdash \gamma &
        \gamma & \bvdash \wht{\alpha}
\end{array}
\end{equation}
%%
It is not hard to show that $\sigma_c(\theta_i) \leq 1$
for all $c$ and all $i < n$. So the sequent
$\theta_0, \theta_1, \dotsc, \theta_{n-1} \bvdash \gamma$
is thin. Certainly $|\gamma| \leq |\wht{\alpha}| = |\alpha| < m$
as well as $|\theta_i| \leq |\wht{\alpha}_i| = |\alpha_i| < m$
for all $i < n$. By Lemma~\ref{duennableitbar} the sequent
$\theta_0, \theta_1, \dotsc, \theta_{n-1} \bvdash \gamma$ is
derivable in $\mathsf{L}_m$. The sequents $\wht{\gamma}_i \bvdash %
\theta_i$, $i < n$, as well as $\gamma \bvdash \wht{\alpha}_n$ are 
axioms of $\mathsf{L}_m$. Hence $\wht{\gamma}_0, \wht{\gamma}_0, \dotsc,
\wht{\gamma}_{n-1} \bvdash \wht{\alpha}$ is derivable in $\mathsf{L}_m$.
We undo the replacement in the derivation. This can in fact
be done by applying a homomorphism (substitution) $t$ which
replaces $\wht{c}$ by $c$. So, we get a derivation of
$\gamma_0, \gamma_1, \dotsc, \gamma_{n-1} \bvdash \gamma_n$ in
$\mathsf{L}_m$. This concludes the proof of Theorem~\ref{reduktion1}.

We remark that Pentus has also shown in \cite{pentus:models} that 
%%%
\index{Pentus, Mati}%%%
%%%%
$\mathsf{L}$ is complete with respect to so--called L--frames. 
%%%
\begin{defn}
%%%
\index{L--frame}%%%
%%%
An \textbf{L--frame} is a free semigroup of the form $\auf A^+, \cdot\zu$. 
A \textbf{valuation} is a function $v : C \pf \wp(A^+)$. $v$ is 
extended to categories and sequents as follows:
%%%
\begin{equation}
\begin{split}
v(\mbox{\mtt ($\alpha\bullet\beta$)}) & := v(\alpha) \cdot v(\beta) \\
v(\mbox{\mtt ($\alpha${\tf}$\beta$)}) & := v(\alpha){/\!/} v(\beta) \\
v(\mbox{\mtt ($\beta${\tb}$\alpha$)}) & := 
	v(\beta){\backslash\!\backslash} v(\alpha) \\
v(\Gamma \circ \Delta) & := v(\Gamma) \cdot v(\Delta)
\end{split}
\end{equation} 
%%%
$\Gamma \bvdash \alpha$ is \textbf{true under} $v$ if $v(\Gamma) \subseteq 
v(\alpha)$. It is \textbf{valid in an L--frame} if it is true under all 
valuations.
\end{defn}
%%%
\begin{thm}[Pentus]
%%%
\index{Pentus, Mati}%%
%%%
$\stackrel{\mathsf{L}}{\leadsto} \Gamma \bvdash \alpha$ iff 
$\Gamma \bvdash \alpha$ is valid in all L--frames.
\end{thm}
%%
A survey of this subject area can be found in \cite{buszkowski:proof}.
%%
\vplatz
\exercise
Prove Theorem~\ref{gruppenwertig}.
%%
\vplatz
\exercise
\label{ex:gerade}
Let $\Gamma \bvdash \alpha$ be derivable in $\mathsf{L}$, $c \in C$. Show
that $\sigma_c(\Gamma) + \sigma_c(\alpha)$ is an even number.
%%
\vplatz
\exercise
Prove Lemma~\ref{reduktion2}.
%%%
\vplatz
\exercise
Show that if $\stackrel{\mathsf{L}}{\leadsto} \Gamma \bvdash \alpha$, 
$\Gamma \bvdash \alpha$ is valid in all L--frames. 
