\section{Semilinear Languages}
%
%
%
In this section we shall study semilinear languages. The notion of 
semilinearity is important in itself as it is widely believed that 
natural languages are semilinear. Whether or not this is case, is 
still open (see Section~\ref{kap2}.\ref{kap2-6}). The issue of 
semilinearity is important, because many grammar formalisms proposed 
in the past only generate semilinear languages (or else are generally 
so powerful that they generate every recursively enumerable set). 
Even though semilinearity in natural languages is the rule rather 
than the exception, the counterexamples show that the grammar 
formalisms do not account for natural language in a satisfactory 
way. 

In this chapter we shall prove a theorem by Ginsburg and Spanier 
%%%
\index{Ginsburg, Seymour}%%%
\index{Spanier, Edwin H.}%%%
%%%%
which says that the semilinear subsets of $\omega^n$ are exactly the 
sets definable in 
%%%
\index{Presburger Arithmetic}%%%
%%%
Presburger Arithmetic. This theorem has numerous consequences, in 
linguistics as well as in mathematics. The proof given here differs 
substantially from the original one. 
%%
\begin{defn}
%%%
\index{monoid!commutative}%%
\index{semigroup!commutative}%%
%%%
A \textbf{commutative monoid} or \textbf{commutative se\-mi\-group 
with unit} is a structure $\auf H, 0, +\zu$ in which the following 
holds for every $x, y, z \in H$.
%%%
\begin{equation}
\label{eq:25commgrp}
\begin{split}
x + 0       & = x \\
x + (y + z) & = (x + y) + z \\
x + y       & = y + x
\end{split}
\end{equation}
\end{defn}
%%
Notice that because of associativity we may dispense with 
brackets. Alternatively, any term can be arbitrarily bracketed 
without affecting its value. We define the notation $\mu \cdot x$ 
as follows: $0 \cdot x := 0$ and $(\mu + 1) \cdot x := \mu \cdot x + x$.
(Later on we shall drop $\cdot$.)
Then $\mu \cdot x_0 + \nu \cdot x_0 = (\mu + \nu) \cdot x_0$, 
and $\mu \cdot (\nu \cdot x_0) = (\mu\nu) \cdot x_0$, simply
by definition. Furthermore, $\mu \cdot (x + y) = 
(\mu \cdot x) + (\mu \cdot y)$, by induction on $\mu$. 
This can be generalized.
%%%
\begin{lem}
\label{lem:commgrpgl}
In a commutative semigroup, the following holds. 
%%%
\begin{align}
\mu \cdot (\sum_{i < m} \nu_i \cdot x_i) & = 
	\sum_{i < m} (\mu\nu_i) \cdot x_i \\
\sum_{i < m} \mu_i \cdot x_i + \sum_{i < m} \nu_i\cdot  x_i & = 
	\sum_{i < m} (\mu_i + \nu_i) \cdot x_i
\end{align}
%%%
\end{lem}
%%%
\proofbeg
Induction on $m$. The case $m = 1$ has been dealt with. Now: 
%%%
\begin{align}
\mu \cdot (\sum_{i < m+1} \nu_i \cdot x_i) & = 
     \mu \cdot (\sum_{i < m} \nu_i \cdot x_i + \nu_m \cdot x_m) \\\notag
   & = \mu \cdot (\sum_{i < m} \nu_i \cdot x_i) + \mu\cdot (\nu_m \cdot x_m)
\\\notag
   & = \sum_{i < m} (\mu\nu_i) \cdot x_i + (\mu\nu_m) \cdot x_m 
\\\notag 
   & = \sum_{i < m+1} (\mu\nu_i) \cdot x_i 
\end{align}
%%%
Also 
%%%
\begin{align}
 & \sum_{i < m+1} \mu_i \cdot x_i + \sum_{i < m+1} \nu_i\cdot  x_i 
\\\notag 
= & (\sum_{i < m} \mu_i \cdot x_i + \mu_m \cdot x_m) 
	+ (\sum_{i < m} \nu_i\cdot  x_i + \nu_m \cdot x_m) \\\notag 
= & (\sum_{i < m} \mu_i \cdot x_i + \sum_{i < m} \nu_i \cdot x_i)  
	+ (\mu_m + \nu_m) \cdot x_m \\\notag 
= & \sum_{i < m} (\mu_i + \nu_i) x_i + (\mu_m + \nu_m) \cdot x_m 
	\\\notag
= & \sum_{i < m+1} (\mu_i + \nu_i) x_i
\end{align}
This finishes the proof.
\proofend

%%%
We shall denote by $M(A)$ set underlying the commutative monoid freely 
generated by $A$. By construction, $\GM(A) := \auf M(A), 0, +\zu$ 
%%%
\index{$\GM(A)$, $\Omega^n$}%%%
%%%
is a commutative
semigroup with unit. What is more, $\GM(A)$ is freely generated by
$A$ as a commutative semigroup. We now look at the set $\omega^n$ of 
all $n$--long sequences of natural numbers, endowed with the operation 
$+$ defined by
%%
\begin{equation}
\auf x_i : i < n\zu + \auf y_i : i< n\zu := \auf x_i + y_i :
i < n\zu 
\end{equation}
%%
This also forms a commutative semigroup with unit. Here the
unit is the sequence $\vec{0}$ consisting of $n$ 0s. We denote this
semigroup by $\Omega^n$. For the following theorem we also need
the so--called
%%%
\index{Kronecker symbol}%%
%%%
\textbf{Kronecker symbol}.
%%
\begin{equation}
\delta^i_j := \begin{cases}
1 & \text{ if i = j,} \\
0 & \text{ otherwise.}
\end{cases}
\end{equation}
%%
\begin{thm}
Let $A = \{a_i : i < n\}$. Let $h$ be the map
which assigns to each element $a_i$ the sequence
$\vec{e}_i = \auf \delta^i_j : j < n\zu$. Then the homomorphism
which extends $h$ is an isomorphism from $\GM(A)$
onto $\Omega^n$.
\end{thm}
%%
\proofbeg
Let $\theta$ be the smallest congruence relation on
$\Tm_{\Omega}(A)$ (with $\Omega \colon 0 \mapsto 0, + \mapsto 2$)
which satisfies \eqref{eq:25commgrp}. It follows from 
Lemma~\ref{lem:commgrpgl} by induction on the level of the 
term $t$ that for $t \in \Tm_{\Omega}(A)$ 
there is a $u\; \theta \; t$ of the form
%%%
\begin{equation}
\label{eq:additive}
u = \sum_{i < n} k_i \cdot a_i
\end{equation}
%%
If \eqref{eq:additive} obtains, put $q(t) := \auf k_i : i < n\zu$. 
Now, it is immediately seen that $\theta = \ker q$, whence 
$\Tm_{\Omega}(A)/\theta \cong \Omega^n$. On the other 
hand, $\Tm_{\Omega}(A)/\theta \cong \GM(A)$, since 
it is easily shown that the first is also freely generated by $A$.
Namely, suppose that $v : a_i \mapsto n_i$ is a map from $A$ into 
$\GN$. Let $\oli{v} : \Tm_{\Omega}(A) \pf N$ be the extension of 
$v$. Then, since $\GN$ is a monoid, $\theta \subseteq \ker \oli{v}$, 
so that we can define a map $q : \goth{Tm}_{\Omega}(A) \pf \GN$ 
such that $\oli{v} = q \circ h_{\theta}$. 
\proofend

This theorem tells us that free commutative semigroups can be
thought of as vectors of numbers. A general element of $M(A)$
can be written down as $\sum_{i < n} k_i \cdot a_i$
where $k_i \in \omega$.

Now we shall define the map $\mu \colon A^{\ast} \pf M(A)$ by
%%
%%%
\index{$\mu$}%%%
%%%%
\begin{equation}
\begin{split}
\mu(\varepsilon)   & = 0    \\
\mu(a_i) & = a_i \\
\mu(\vec{x} \conc \vec{y}) & = \mu(\vec{x}) + \mu(\vec{y})
\end{split}
\end{equation}
%%
This map is a homomorphism of monoids and also surjective.
It is not injective, except in the case where $A$ consists
of one element only. The map
%%%
\index{Parikh map}%%
%%%
$\mu$ is called the \textbf{Parikh map}. We have
%%
\begin{equation}
\mu\left(\prod_{i < k} \vec{x}_i\right) =
\sum_{i < k} \mu(\vec{x}_i) 
\end{equation}
%%
\begin{defn}
%%%
\index{letter equivalence}%%
%%%
Two languages $L, M \subseteq A^{\ast}$ are called
\textbf{letter equivalent} if we have $\mu[L] = \mu[M]$.
\end{defn}
%%
\begin{defn}
\label{defn:semi}
%%%
\index{language!linear}%%
\index{language!semilinear}%%
%%%
Elements of $M(A)$ will also be denoted using vector arrows. Moreover, 
if $\vec{x} \in \omega^n$ we write $\vec{x}(i)$ for the $i^{\text{th}}$ 
component of $\vec{x}$. A set $U \subseteq M(A)$ is called \textbf{linear} 
if for some $\alpha \in \omega$ and some $\vec{u}, \vec{v}_i \in M(A)$
%%
\begin{equation}
U = \{\vec{u} + \sum_{i < \alpha} k_i \cdot \vec{v}_i : k_0, \dotsc, 
    k_{\alpha-1}\in \omega\} 
\end{equation}
%%
The $\vec{v}_i$ are called \textbf{cyclic vectors of} $U$.
%%%
\index{vector!cyclic}%%
\index{dimension}%%
%%%
The smallest $\alpha$ for which $U$ has such a representation
is called the \textbf{dimension of} $U$.  $U$ is said to be
\textbf{semilinear} if $U$ is the finite union of linear sets.
A language $L \subseteq A^{\ast}$ is called \textbf{semilinear}
if $\mu[L]$ is semilinear.  
\end{defn}
%%
We can denote semilinear sets rather compactly as follows.
If $U$ and $V$ are subsets of $M(A)$ then write
$U + V := \{\vec{x} + \vec{y} : \vec{x} \in U, \vec{y} \in V\}$. 
%%%%
\index{$U + V$, $nU$, $\omega U$}%%%
%%%%
Further, let $\vec{x} + U := \{\vec{x} + \vec{y} : \vec{y} \in U\}$. 
So, vectors are treated as singleton sets. Also, we write 
$n U := \{n\vec{x} : n \in \omega\}$. Finally, we denote by 
$\omega U$ the union of all $n U$, $n \in \omega$. With these 
abbreviations we write the set $U$ from Definition~\ref{defn:semi} 
as follows.
%%
\begin{equation}
U = \vec{u} + \omega \vec{v}_0 + \omega \vec{v}_1 + \dotsb + 
\omega \vec{v}_{\alpha-1} 
\end{equation}
%%
This in turn we abbreviate by
%%
\begin{equation}
U = \vec{u} + \sum_{i < \alpha} \omega \vec{v}_i
\end{equation}
%%%
Finally, for $V = \{\vec{v}_i : i < \alpha\}$
%%%
\index{$\Sigma(U;V)$}%%
%%%%
\begin{equation}
\Sigma(U;V) := U + \sum_{i < \alpha}  \omega \vec{v}_i
\end{equation}
%%
\begin{lem}
\label{lem:sigmaeig}
The following holds.
\begin{dingautolist}{192}
\item $\Sigma(U;V) \cup \Sigma(U';V) = \Sigma(U \cup U';V)$.
\item $\Sigma(U;V) + \Sigma(U';V') = \Sigma(U + U'; V\cup V')$.
\item $\omega \Sigma(U;V) = \Sigma(\{\vec{0}\};U \cup V)$. 
\end{dingautolist}
\end{lem}
%%
\index{Parikh, Rohit}%%%
%%%%
\begin{thm}[Parikh]
A language is semilinear iff it is letter equivalent to a
regular language.
\end{thm}
%%
\proofbeg
$(\Pf)$ It is enough to show this for linear languages. Suppose 
that $\pi[L] = \Sigma(\{\vec{u}\};V)$, $V = \{\vec{v}_i : i < n\}$. 
Pick a string $\vec{x}$ and $\vec{y}_i$, $i < n$, such that 
$\pi(\vec{x}) = \vec{u}$ and $\pi(\vec{y}_i) = \vec{v}_i$ for 
all $i < n$. Put  
%%%
\begin{equation}
M := \vec{x}\conc (\bigcup_{i < n} \vec{y}_i)^{\ast}
\end{equation}
%%%
Clearly, $M$ is regular and letter equivalent to $L$.
$(\Leftarrow)$ By induction on the length of the regular term $R$
we shall show that $\mu[L(R)]$ is semilinear. This is clear for
$R = a_i$ or $R = \varepsilon$. It is also clear for
$R = S_1 \cup S_2$. Now let $R = S_1 \cdot S_2$. Using the equations 
$(S \cup T) \cdot U = S \cdot U \cup T \cdot U$
and $U \cdot (S \cup T) = U \cdot S \cup U \cdot T$, we can 
assume that $S_1$ and $S_2$ are linear. Then by definition 
$\mu[L(S_1)] = \Sigma(\{\vec{u}\};C_1)$ and 
$\mu[L(S_2)] = \Sigma(\{\vec{v}\};C_2)$, for certain $\vec{u}$, 
$\vec{v}$, and sets $C_1$ and $C_2$. Then, using 
Lemma~\ref{lem:sigmaeig}, we get
%%
\begin{equation}
\mu[L(R)] = \Sigma(\{\vec{u}\};C_1) + \Sigma(\{\vec{v}\};C_2) = 
\Sigma(\{\vec{u}+\vec{v}\};C_1\cup C_2)
\end{equation}
%%
Now, finally, $R = S^{\ast}$. If $S = T \cup U$,
then $R = (T^{\ast} \cdot U^{\ast})^{\ast}$, so that we may
again assume that $S$ is linear, say, $S = \Sigma(\{\vec{u}\}; C)$ 
for some $\vec{u}$ and $C$. By Lemma~\ref{lem:sigmaeig} 
%%
\begin{equation}
\mu[L(R)] = \omega\Sigma(\{\vec{u}\};C) = \Sigma(\{\vec{0}\};\{\vec{u}\} 
\cup C)
\end{equation}
%%
Hence $R$ too is linear. This ends the proof.
\proofend
%%

We draw a useful conclusion from the definitions.
%%
\begin{thm}
Let $A$ be a (possibly infinite) set. The set of semilinear
languages over $A$ form an AFL with the exception that the
intersection of a semilinear language with a regular language
need not be semilinear.
\end{thm}
%%
\proofbeg
Closure under union, star and concatenation are immediate.
We have to show that semilinear languages are closed under
homomorphisms and inverse homomorphisms. The latter is again
trivial. Now let $v \colon A \pf A^{\ast}$ be a homomorphism.
$v$ induces a map $\kappa_v \colon \GM(A) \pf \GM(A)$.
The image under $\kappa_v$ of a semilinear set is semilinear.
For given a string $\vec{x} \in A^{\ast}$ we have
$\mu(\oli{v}(\vec{x})) = \kappa_v(\mu(\vec{x}))$, as is easily
checked by induction on the length of $\vec{x}$.
Let $M$ be linear, say $M = \vec{u} + \sum_{i < k} \omega \cdot
\vec{v}_i$. Then
%%
\begin{equation}
\kappa_v[M] = \kappa_v(\vec{u}) + \sum_{i < k} \omega 
\kappa_v(\vec{v}_i) 
\end{equation}
%%
From this the claim follows. Hence we have
$\mu[\oli{v}[L]] = \kappa_v[\mu[L]]$. The right hand side is
semilinear as we have seen. Finally, take the language
$L := \{\mbox{\tt a}^{2^i}\mbox{\tt b}^{2^i} : i \in \omega\}
\cup \{\mbox{\tt b}^j\mbox{\tt a}^j : j \in \omega\}$.
$L$ is semilinear. $L \cap \mbox{\tt a}^{\ast}\mbox{\tt b}^{\ast}
= \{\mbox{\tt a}^{2^i}\mbox{\tt b}^{2^i} : i \in \omega\}$
is not semilinear, however.
\proofend
%%

Likewise, a subset of $\BZ^n$ ($\BQ^n$) is called \textbf{linear} if it 
has the form
%%
\begin{equation}
\vec{v}_0 + \BZ \vec{v}_1 + \BZ \vec{v}_2 + \dotsb + \BZ \vec{v}_m
\end{equation}
%%
for subsets of $\BZ^n$ as well as 
%%
\begin{equation}
\vec{v}_0 + \BQ \vec{v}_1 + \BQ \vec{v}_2 + \dotsb + \BQ \vec{v}_m
\end{equation}
%%
for subsets of $\BQ^n$. The linear subsets of $\BQ^n$ are nothing but 
the affine subspaces. A subset of $\omega^n$ ($\BZ^n$, $\BQ^n$) is called 
\textbf{semilinear} if it is the finite union of linear sets. 

Presburger Arithmetic is defined as follows. The basic symbols are 
$\mbox{\mtt 0}$, $\mbox{\mtt 1}$, $\mbox{\mtt +}$, $\mbox{\mtt <}$ 
and $\mbox{\mtt \symbol{30}}_m$, $m \in \omega - \{0,1\}$. 
Then Presburger Arithmetic is the set of first order sentences which 
are valid in $\uli{\BZ} := \auf \BZ, 0, 1, +, <, %%
\auf \equiv_m : 1 < m \in \omega\zu\zu$, where $a \equiv_m b$ iff 
$a - b$ is divisible by $m$ (for FOL see Sections~\ref{kap3}.\ref{kap3-6} 
and \ref{kap6}.\ref{kap6-4a}). 

Negation can be eliminated. Notice namely that $\mbox{\mtt \symbol{5}%
(x}_0$=x$_1\mbox{\mtt )}$ is equivalent to {\mtt (x$_0$<x$_1$)%
\symbol{31}(x$_1$<x$_0$)}, {\mtt \symbol{5}(x$_0$<x$_1$)} to 
{\mtt (x$_0$=x$_1$)\symbol{31}(x$_1$<x$_0$)}
and {\mtt \symbol{5}(x$_0$\symbol{30}$_m$x$_1$)} is equivalent to 
{\mtt $\goder_{0 < n < m}$x$_0$\symbol{30}$_m$(x$_1$+$\uli{n}$)}. 
Here, $\uli{n}$ is defined by $\uli{0} := \mbox{\mtt 0}$, 
$\uli{n+1} := \mbox{\mtt ($\uli{n}$+1)}$. We shall 
use {\mtt x$_0$\symbol{28}x$_1$} for 
{\mtt (x$_0$<x$_1$)\symbol{31}(x$_0$=x$_1$)}. Moreover, multiplication 
by a given natural number also is definable: put $0t := \oli{0}$, and 
$(n+1)t := \mbox{\mtt (}nt \mbox{\mtt +} t\mbox{\mtt )}$. Every term 
in the variables {\mtt x$_i$}, $i < n$, is equivalent to 
a term {\mtt x$_0$+$\sum_{i < n}a_i$x$_i$}, where $b, a_i \in \omega$, 
$i < n$. A subset $S$ of $\BZ^n$ is \textbf{definable} 
%%%%
\index{definability}%%
%%%%
if there is a formula $\varphi(\mbox{\mtt x}_0, \mbox{\mtt x}_1, \dotsc, %
\mbox{\mtt x}_{n-1})$ such that 
%%
\begin{equation}
S = \{\auf k_i : i < n\zu \in \BZ^n : \uli{\BZ} \vDash 
	\varphi[k_0, k_1, \dotsc, k_{n-1}]\}
\end{equation}
%%%
The definable subsets of $\BZ^n$ are closed under union, intersection 
and complement and permutation of the coordinates. Moreover, if 
$S \subseteq \BZ^{n+1}$ is definable, so is its projection 
%%
\begin{multline}
\pi_n[S] := \{\auf k_i : i < n\zu : \text{ there is }
k_n \in \BZ \text{ such that } \\
		\auf k_i : i < n+1\zu \in S\}
\end{multline}
%%%
The same holds for definable subsets of $\omega^n$, which are simply 
those definable subsets of $\BZ^n$ that are included in $\omega^n$.
Clearly, if $S \subseteq \BZ^n$ is definable, so is $S \cap \omega^n$.
%%%
\begin{lem}
Suppose that $a + \sum_{i < n} p_i x_i = b + \sum_{i < n} q_i x_i$ 
is a linear equation with rational numbers $a$, $b$, $p_i$ and 
$q_i$ ($i < n$). Then there is an equation 
%%%
\begin{equation}
g + \sum_{i < n} u_i x_i = h + \sum_{i < n} v_i x_i
\end{equation}
%%% 
with the same solutions, but with positive integer coefficients such 
that $g \cdot h = 0$ and for every $i < n$: $v_i u_i = 0$.
\end{lem}
%%%
\proofbeg
First, multiply with the least common denominator to transform the 
equation into an equation with integer coefficients. Next, add 
$-p_ix_i$ to both sides if $p_i < 0$, unless $q_i < p_i < 0$, in 
which case we add $- q_i x_i$. Now all coefficients are positive. 
Next, for every $i < n$, substract $q_i x_i$ from both sides if 
$p_i > q_i$ and $p_i x_i$ otherwise. These transformations preserve 
the set of solutions.
\proofend
%%%

Call an equation \textbf{reduced} if it has the form 
%%%
\index{equation!reduced}%%%
%%%%
%%
\begin{equation}
g + \sum_{i < m} k_i x_i = \sum_{m \leq i < n} k_i x_i
\end{equation}
%%
with positive integer coefficients $g$ and $k_i$, $i < n$. 
Likewise for an inequation. Evidently, modulo renaming of 
variables we can transform every rational equation into 
reduced form.
%%%
\begin{lem}
\label{lem:eq}
The set of solutions of a reduced equation is semilinear.
\end{lem}
%%%
\proofbeg
Let $\mu$ be the least common multiple of the $k_i$. 
Consider a vector of the form $\vec{c}_{i,j} = (\mu/k_i)\vec{e}_i + 
(\mu/k_j)\vec{e}_j$, where $i < m$ and $m \leq j < n$. Then 
if $\vec{v}$ is a solution, so is $\vec{v} + \vec{c}_{i,j}$ and conversely. 
Put $C := \{\vec{c}_{i,j} : i < m \leq j < n\}$ and 
%%
\begin{equation}
P := \left\{\vec{u} : g + \sum_{i < m} k_i \vec{u}(i) = \sum_{m \leq i 
< n} k_i \vec{u}(i), \vec{u}(i) < \mu/k_i\right\}
\end{equation}
%%
Both $P$ and $C$ are finite. Moreover, the set of solutions is 
exactly $\Sigma(P;C)$. 
\proofend
%%%
\begin{lem}
\label{lem:ineq}
The set of solutions of a reduced inequation is semilinear.
\end{lem}
%%
\proofbeg
Assume that the inequation has the form
%%
\begin{equation}
g + \sum_{i < m} k_i x_i \leq \sum_{m \leq i < n} k_i x_i
\end{equation}
%%%
Define $C$ and $P$ as before. Let $E := \{\vec{e}_i : m \leq i < n\}$.
Then the set of solutions is $\Sigma(P;C \cup E)$. If the inequation 
has the form
%%
\begin{equation}
g + \sum_{i < m} k_i x_i \geq \sum_{m \leq i < n} k_i x_i
\end{equation}
%%%
The set of solutions is $\Sigma(P;C \cup F)$, where 
$F := \{\vec{e}_i : i < m\}$.
\proofend
%%%
\begin{lem}
Let $M \subseteq \BQ^n$ be an affine subspace. Then $M \cap \BZ^n$ 
is a semilinear subset of $\BZ^n$.
\end{lem}
%%%
\proofbeg
Let $\vec{v}_i$, $i < m+1$, be vectors such that 
%%
\begin{equation}
M = \vec{v}_0 + \BQ \vec{v}_1 + \BQ \vec{v}_2 + \dotsb + 
\BQ \vec{v}_{m-1}
\end{equation}
%%
We can assume that the $\vec{v}_i$ are linearly independent. 
Clearly, since $\BQ \vec{w} = \BQ (\lambda \vec{w})$ for any 
nonzero rational number $\lambda$, we can assume that 
$\vec{v}_i \in \BZ^n$, $i < m$.
Now, put 
%%%
\begin{equation}
V := \{\vec{v}_0 + \sum_{0 < i < m} \lambda_i \vec{v}_i : 
0 \leq \lambda_i < 1\}
\end{equation}
%%%
$V \cap \BZ^n$ is finite. Moreover, if 
$\vec{v}_{0} + \sum_{0 < i < m} \kappa_i \vec{v}_i \in \BZ^n$ 
then $\vec{v}_{0} + \sum_{0 < i < m} \kappa_i' \vec{v}_i 
\in \BZ^n$ if $\kappa_i - \kappa_i' \in \BZ$. Hence, 
%%%
\begin{equation}
M = \bigcup_{\vec{w} \in V} \left(\vec{w} + 
	\BZ \vec{v}_1 + \dotsb + \BZ \vec{v}_m\right)
\end{equation}
%%
This is a semilinear set.
\proofend
%%%
\begin{lem}
Let $M \subseteq \BZ^n$ be a semilinear subset of $\BZ^n$. Then 
$M \cap \omega^n$ is semilinear. 
\end{lem}
%%%
\proofbeg
It suffices to show this for linear subsets.
Let $\vec{v}_i$, $i < m+1$, be vectors such that 
%%
\begin{equation}
M = \vec{v}_0 + \BZ \vec{v}_1 + \BZ \vec{v}_2 + \dotsb + 
\BZ \vec{v}_{m-1}
\end{equation}
%%
Put $\vec{w}_i := - \vec{v}_i$, $0 < i < m$. Then 
%%
\begin{equation}
M = \vec{v}_0 + \omega \vec{v}_1 + \omega \vec{v}_2 + \dotsb + 
\omega \vec{v}_{m-1} + \omega \vec{w}_1 + \dotsb + \omega \vec{w}_{m-1}
\end{equation}
%%
Thus, we may without loss of generality assume that 
%%
\begin{equation}
M = \vec{v}_0 + \omega \vec{v}_1 + \omega \vec{v}_2 + \dotsb + 
\omega \vec{v}_{m-1}
\end{equation}
%%
Notice, however, that these vectors are not necessarily in $\omega^n$. 
For $i$ starting at 1 until $n$ we do the following. 

Let $x^i_j := \vec{v}_j(i)$. Assume that for $0 < j < p$ we have 
$x^i_j \geq 0$, and that for $p \leq j < m$ we have $x^i_j > 0$. 
(A renaming of the variables can achieve this.) We introduce new 
cyclic vectors $\vec{c}_{j,k}$ for $0 < j < p$ and $p \leq k < m$. 
Let $\mu$ the least common multiple of the $|x^i_s|$, for all 
$0 < s < m$ where $x^i_s \neq 0$. 
%%%
\begin{equation}
\vec{c}_{i,j} := (\mu/x^i_j) \vec{v}_j + (\mu/x^i_k)\vec{v}_k
\end{equation}
%%%
Notice that the $s$--coordinates of these vectors are positive 
for $s < i$, since this is a positive sum of positive numbers. 
The $i$th coordinate of these vectors is 0. Suppose that the 
$i$th coordinate of 
%%
\begin{equation}
\vec{w} = \vec{v}_0 + \sum_{0 < j < m} \lambda_j \vec{v}_j
\end{equation}
%%
is $\geq 0$, where $\lambda_j \in \omega$ for all $0 < j < m$. Suppose 
further that for some $k \geq p$ we have 
$\lambda_k \geq v^i_0 + m(\mu/|x^i_k|)$. 
Then there must be a $j < p$ such that $\lambda_j \geq 
(\mu/x^i_j)$. Then put $\lambda_r' := \lambda_r$ for 
$r \neq j,k$, $\lambda_j' := \lambda_j - (\mu/x^i_j)$ and 
$\lambda_k' := \lambda_k + (\mu/x^i_k)$. Then
%%
\begin{equation}
\vec{w} = \vec{c}_{j,k} + \sum_{0 < j < m} \lambda_j' \vec{v}_j
\end{equation}
%%
Moreover, $\lambda_j' \leq \lambda_j$ for all $j < p$, and 
$\lambda_k' < \lambda_k$. Thus, by adding these cyclic vectors 
we can see to it that the coefficients of the $\vec{v}_k$ 
for $p \leq k < m$ are bounded. Now define $P$ to be the set of 
all $\vec{w}$ which have a decomposition
%%%
\begin{equation}
\vec{w} = \vec{v}_0 + \sum_{0 < j < m} \lambda_j \vec{v}_j \in \omega^n
\end{equation}
%%
where $\lambda_j < v^j_0 + m |\mu/x^i_j|$ for all $0 < j < m$.
%%%
Then 
%%%
\begin{equation}
M \cap \omega^n = \bigcup_{\vec{u} \in P} \left(\vec{u} + 
	\sum_{0 < j < p} \lambda_j \vec{v}_j + 
	\sum_{0 < j < p \leq k < m} \kappa_{j,k} \vec{c}_{j,k}\right)
\end{equation}
%%%
with all $\lambda_j$, $\kappa_{j,k} \geq 0$. Now we have achieved that 
all $j$th coordinates of vectors are positive. 
%%
\proofend

The following is now immediate. 
%%%
\begin{lem}
\label{lem:QtoN}
Let $M \subseteq \BQ^n$ be an affine subspace. Then $M \cap \omega^n$ 
is a semilinear subset of $\omega^n$.
\end{lem}
%%
\begin{lem}
\label{lem:intersection}
The intersection of semilinear sets is again semilinear.
\end{lem}
%%%
\proofbeg
It is enough to show the claim for linear sets. So, let $S_0$ and 
$S_1$ be linear. Then there are $C_0 = \{\vec{u}_i : i < m\}$ and 
$C_1 = \{\vec{v}_i : i < n\}$ and $\vec{u}$ and $\vec{v}$ such 
that $S_0 = \Sigma(\{\vec{u}\}; C_0)$ and $S_1 := \Sigma(\{\vec{v}\}; C_1)$. 
Notice that $\vec{w} \in S_0 \cap S_1$ iff there are 
natural numbers $\kappa_i$ ($i < m$) and $\lambda_j$ ($j < n$) such that 
%%
\begin{equation}
\vec{w} = \vec{u} + \sum_{i < m} \kappa_i \vec{u}_i = \vec{v} + 
\sum_{i < n} \lambda_i \vec{v}_i
\end{equation}
%%
So, we have to show that the set of these $\vec{w}$ is semilinear. 

The equations are now taken as linear equations with $\kappa_i$, 
$i < m$ and $\lambda_i$, $i < n$, as variables. Thus we have 
equations  for $m + n$ variables. We solve these equations first 
in $\BQ^{m+n}$. The solutions form an affine subspace $V \subseteq \BQ^{m+n} 
\cong \BQ^m \oplus \BQ^n$. By Lemma~\ref{lem:QtoN}, 
$V \cap \omega^{m+n}$ is semilinear, and so is its projection 
onto $\omega^m$ (or to $\omega^n$ for that matter). Let it be 
$\bigcup_{i < p} L_i$, where for each $i < p$, $L_i \subseteq 
\omega^m$ is linear. Thus there is a representation of $L_i$ as 
%%
\begin{equation}
L_i = \vec{\theta} + \omega \vec{\eta}_0 + \dotsb +
\omega \vec{\eta}_{\gamma-1}
\end{equation}
%%
Now put 
%%%
\begin{equation}
W_i := \{\vec{u} + \sum_{i < m} \vec{\kappa}(i) \vec{u}_i : 
	\vec{\kappa} \in L_i\}
\end{equation}
%%%
From the construction we get that 
%%
\begin{equation}
S_0 \cap S_1 = \bigcup_{i < p} W_i
\end{equation}
%%%
Define vectors $\vec{q}_i := \sum_{j < m} \vec{\eta}_i(j) \vec{u}_i$, 
$i < \gamma$ and $\vec{r} := \vec{c} + \sum_{j < m} \vec{\theta}(j)
\vec{u}_i$. Then 
%%%
\begin{equation}
W_i = \vec{r} + \omega \vec{q}_0 + \dotsb + \omega \vec{q}_{\gamma-1}
\end{equation}
%%%
So, the $W_i$ are linear. This shows the claim.
\proofend
%%%
\begin{lem}
If $S \subseteq \omega^n$ is semilinear, so is its projection $\pi_n[S]$.
\end{lem}
%%%
We need one more prerequisite. Say that a first--order theory $T$ has 
\textbf{quantifier elimination} 
%%%
\index{quantifier elimination}%%%
%%%%
if for every formula $\varphi(\vec{x})$ 
there exists a quantifier free formula $\chi(\vec{x})$ such that 
$T \vdash \varphi(\vec{x})\boldsymbol{\dpf}\chi(\vec{x})$. We follow 
the proof of \cite{monk:logic}. 
%%%
\index{Presburger}%%%
%%%
\begin{thm}[Presburger]
\label{thm:qe}
Presburger Arithmetic has quantifier elimination. 
\end{thm}
%%%
\proofbeg
It is enough to show that for every formula $\mbox{\mtt 
(\symbol{21}x}_{\snull}\mbox{\mtt)}\varphi(\vec{y}, %
\mbox{\mtt x}_{\snull})$ with $\varphi(\vec{y},x)$ quantifier free 
there exists a quantifier free formula $\chi(\vec{y})$ such that 
%%%
\begin{equation}
\BZ \vDash \mbox{\mtt (\symbol{20}$\vec{y}$)(\symbol{21}x$_{\snull}$%
)($\varphi(\vec{y},\mbox{\mtt x}_0)\boldsymbol{\dpf}\chi(\vec{y})$)}
\end{equation}
%%%
We may further eliminate negation (see the remarks above) 
and disjunctions inside $\varphi(\vec{y},x)$ (since 
{\mtt (\symbol{21}x$_{\snull}$)($\alpha$\symbol{31}$\beta$)} is 
equivalent with {\mtt ((\symbol{21}x$_{\snull}$)$\alpha$)\symbol{31}%
((\symbol{21}x$_{\snull}$)$\beta$)}. Finally, we may assume that all 
conjuncts contain {\mtt x$_{\snull}$}. For if $\alpha$ does not contain 
{\mtt x$_{\snull}$} free, {\mtt (\symbol{21}x$_{\snull}$)($\alpha$\symbol{4}%
$\beta$)} is equivalent to {\mtt ($\alpha$\symbol{4}(\symbol{21}x$_{\snull}$%
)$\beta$)}. So, $\varphi$ can be assumed to be a conjunction 
of atomic formulae of the following form: 
%%%
\begin{multline}
\mbox{\mtt (\symbol{21}x$_{\snull}$)($\gund_{i < p} n_i$x$_{\snull}$%
\mbox{\mtt\symbol{61}}$t_i$\symbol{4}$\gund_{i < q} 
n'_i$x$_{\snull}$<$t'_i$\symbol{4}$\gund_{i < r} n''_i$x$_{\snull}$>$t''_i$}
\\
\mbox{\mtt \symbol{4}$\gund_{i < s} n'''_i$x$_{\snull}$\symbol{30}$_{m_i}%
t'''_i$)}
\end{multline}
%%%
Since {\mtt $s\,$\symbol{30}$_mt$} is equivalent with 
{\mtt $ns\,$\symbol{30}$_m nt$}, so after suitable 
multiplication we may see to it that all the $n_i$, $n'_i$, $n''_i$ 
and $n'''_i$ are the same number $\nu$. 
%%%
\begin{multline}
\mbox{\mtt (\symbol{21}x$_{\snull}$)($\gund_{i < p} \nu$x$_{\snull}$%
\mbox{\mtt\symbol{61}}$\tau_i$\symbol{4}% 
$\gund_{i < q} \nu$x$_{\snull}$<$\tau'_i$\symbol{4}%
$\gund_{i < r} \nu$x$_{\snull}$>$\tau''_i$} \\
\mbox{\mtt \symbol{4}$\gund_{i < s}\nu$x$_{\snull}%
$\symbol{30}$_{m_i} \tau'''_i$)}
\end{multline}
%%%
We may rewrite the formula in the following way (replacing 
{\mtt $\nu$x$_{\snull}$} by {\mtt x$_{\snull}$} and adding 
instead the condition that {\mtt x$_{\snull}$} is divisible by $\nu$). 
%%%
\begin{multline}
\mbox{\mtt (\symbol{21}x$_{\snull}$)(x$_{\snull}$\symbol{30}$_{\nu}%
$0\symbol{4}%
$\gund_{i < p}$x$_{\snull}$\mbox{\mtt\symbol{61}}$\tau_i$\symbol{4}%
$\gund_{i < q}$x$_{\snull}$<$\tau'_i$\symbol{4}% 
$\gund_{i < r}$x$_{\snull}$>$\tau''_i$} \\%
\mbox{\mtt \symbol{4}$\gund_{i < s}$x$_{\snull}$\symbol{30}$_{m_i}\tau'''_i$)}
\end{multline}
%%%
Assume that $p > 0$. Then the first set of conjunctions is equivalent 
with the conjunction of 
$\gund_{i < j < p} \tau_i\mbox{\mtt\symbol{61}}\tau_j$ (which 
does not contain {\mtt x$_{\snull}$}) and 
{\mtt x$_{\snull}$\mbox{\symbol{61}}$\tau_0$}. We may therefore 
eliminate all occurrences of {\mtt x$_{\snull}$} by $\tau_0$ in 
the formula. 

Thus, from now on we may assume that $p = 0$. Furthermore, notice that 
{\mtt (x$_{\snull}$<$\sigma$\symbol{4}x$_{\snull}$<$\tau$)} is equivalent to
{\mtt (x$_{\snull}$<$\sigma$\symbol{4}$\sigma$\symbol{28}$\tau$)\symbol{31}(x%
$_{\snull}$<$\tau$\symbol{4}$\tau$<$\sigma$)}. This means that we can assume 
$q \leq 1$, and likewise that $r \leq 1$. Next we show that we can 
actually have $s \leq 1$. To see this, notice the following. 
%%%%
\begin{quote}
Let $u,v,w,x$ be integers, $w, x > 1$, and let $p$ be the least 
common multiple of $w$ and $x$. Then $\gcd(p/w, p/x) = 1$, 
and so there exist integers $m, n$ such that  $1 = m \cdot p/w + 
n \cdot p/x$. It follows that the following are equivalent. 
%%%%
\begin{dingautolist}{192}
\item $y \equiv u \pmod{w}$ and $y \equiv v \pmod{x}$ 
\item $u \equiv v \pmod{\gcd(w,x)}$ and 
	$y \equiv m(p/w)u + n(p/x)v \pmod{p}$. 
\end{dingautolist} 
\end{quote}
%%%%
The Euclidean algorithm yields numbers $m$ and $n$ as required 
(see \cite{jones:numbertheory}). Now suppose that the first obtains.  
Then $y - u = ew$ and $y - v = fx$ for some numbers $e$ and $f$. 
Then $u - v = fx - ew$, which is divisible by $\gcd(x,w)$. 
So, $u \equiv v \pmod{\gcd(w,x)}$. Furthermore, 
%%%
\begin{align}
y - m(p/w)u - n(p/x)v & = m(p/w)y + n(p/x)y \\\notag
		& \quad - m(p/w)u - n(p/x)v \\\notag
		& = m(p/w)(y - u) \\\notag
		& \quad + n(p/x)(y - v) \\\notag
		& = m(p/w)em + n(p/x)fn  \\\notag
		& \equiv 0 \pmod{p} 
\end{align}
%%%
So, the second holds. Conversely, if the second holds, then for 
some $k$ we have $u - v = k \gcd(w,x)$. Then 
%%%
\begin{align}
y - u           & = y - m(p/w)u - n(p/x)u \\\notag
		& = y - m(p/w)u - n(p/x)v - 
		n(p/x)k \cdot \gcd(m,n)\\\notag
		& \equiv 0 \pmod{w} 
\end{align}
%%%
Analogously $y \equiv v \pmod{x}$ is shown. 
		  
Using this equivalence we can reduce the congruence statements to 
a conjunction of congruences where only one involves {\mtt x$_{\snull}$}. 

This leaves us with 8 possibilities. If $r = 0$ or $s = 0$ the 
formula is actually trivially true. So, 
{\mtt (\symbol{21}x$_{\snull}$)(x$_{\snull}$<$\tau$)}, 
{\mtt (\symbol{21}x$_{\snull}$)($\upsilon$<x$_{\snull}$)}, 
{\mtt (\symbol{21}x$_{\snull}$)(x$_{\snull}$\symbol{61}$_m\xi$)}, 
as well as
{\mtt (\symbol{21}x$_{\snull}$)(x$_{\snull}$<$\tau$\symbol{4}x%
$_{\snull}$\symbol{30}$_m\xi$)} 
and {\mtt (\symbol{21}x$_{\snull}$)($\upsilon$<x$_{\snull}%
$\symbol{4}x$_{\snull}$\symbol{30}$_m \xi$)}  can all be dropped 
or replaced by $\boldsymbol{\top}$. Finally, {\mtt (\symbol{21}x%
$_{\snull}$)(x$_{\snull}$<$\tau$\symbol{4}$\upsilon$<x$_{\snull}$)} 
is equivalent with  {\mtt $\upsilon$+1<$\tau$} and 
{\mtt (\symbol{21}x$_{\snull}$)(x$_{\snull}$<$\tau$\symbol{4}$\upsilon$%
<x$_{\snull}$\symbol{4}x$_{\snull}$\symbol{61}$_m \xi$)} is equivalent with
{\mtt $\goder_{i < m}$($\tau$+1+$i$<$\upsilon$\symbol{4}% 
$\tau$+1+$i$\symbol{30}$_m \xi$)}.
This shows the claim.
\proofend
%%%
\nocite{ginsburgspanier:presburger}
\nocite{ginsburgspanier:semilinear}
\index{Ginsburg, Seymour}%%
\index{Spanier, Edwin H.}%%%
\begin{thm}[Ginsburg \& Spanier]
\label{thm:semabschluss}
A subset of $\omega^n$ is se\-mi\-li\-ne\-ar iff it is definable 
in Presburger Arithmetic. 
\end{thm}
%%%
\proofbeg
($\Pf$) Every semilinear set is definable in Presburger Arithmetic.
To see this it is enough to show that linear sets are definable. For 
if $M$ is a union of $N_i$, $i < p$, and each $N_i$ is linear and 
hence definable by a formula $\varphi_i(\vec{x})$, then $M$ is 
definable by $\goder_{i < p} \varphi_i(\vec{x})$. Now let 
$M = \vec{v} + \omega \vec{v}_0 + \dotsb + \omega \vec{v}_{m-1}$ be 
linear. Then put 
%%%
\begin{multline}
\varphi(\vec{x}) := \mbox{\mtt (\symbol{21}x$_n$)(\symbol{21}%
x$_{n+1}$)$\dotsb$(\symbol{21}x$_{n+m-1}$)($\gund_{i < m}$0\symbol{28}%
x$_{n+i}$} \\
 	\mbox{\mtt \symbol{4}$\gund_{i < n}$($\vec{v}(i)$%
+$\sum_{j < m}$x$_{n+i}\vec{v}(i)_j$=x$_{i}$))}
\end{multline}
%%%
$\varphi(\vec{x})$ defines $M$. ($\Leftarrow$) Let $\varphi(\vec{x})$ be a 
formula defining $S$. By Theorem~\ref{thm:qe}, there exists a 
quantifier free formula $\chi(\vec{x})$ defining $S$. Moreover, 
as we have remarked above, $\chi$ can be assumed to be negation free. 
Thus, $\chi$ is a disjunction of conjunctions of atomic formulae. 
By Lemma~\ref{lem:intersection}, the set of semilinear subsets of 
$\omega^n$ is closed under intersection of members, and it is also closed  
under union. Thus, all we need to show is that atomic formulae 
define semilinear sets. Now, observe that 
{\mtt x$_{\snull}$\symbol{30}$_m$x$_{\seins}$} is equivalent to 
{\mtt (\symbol{21}x$_{\szwei}$)(x$_{\snull}$=x$_{\seins}$+$m$x$_{\szwei}$)}, 
which is semilinear, as it is the projection of 
{\mtt x$_{\snull}$=x$_{\seins}$+$m$x$_{\szwei}$} 
onto the first two components. 
\proofend
%%%
\vplatz
\exercise
Let $|A| = 1$. Show that $\GZ(A)$ is isomorphic to $\GM(A)$.
Derive from this that there are only countably many semilinear 
languages over $A$.
%%%
\vplatz
\exercise
Let $L \subseteq A^{\ast}$. Call $L$ \textbf{almost periodical} if there 
%%%
\index{language!almost periodical}%%%
%%%
are numbers $p$ (the modulus of periodicity) and $n_0$ such that 
for all $\vec{x} \in L$ with length $\geq n_0$ there is a string 
$\vec{y} \in L$ such that $|\vec{y}| = |\vec{x}| + p$. Show that 
a semilinear language is almost periodical.  
%%%
\vplatz %%
\exercise %%
\label{ex:semilincont}%%
Let $A = \{\mbox{\tt a},
\mbox{\tt b}\}$. Further, let $U := \mbox{\tt a}^{\ast} \cup
\mbox{\tt b}^{\ast}$. Now let $N \subseteq M(A)$ be a set such
that $N - U$ is infinite. Show that there are $2^{\aleph_0}$ many
languages $L$ with $\mu[L] = N$. (The cardinality of
$A^{\ast}$ is $\aleph_0$, hence there can be no more than
$2^{\aleph_0}$ such languages. The exercise consists in 
showing that there are no less of them either.)
%%%%
\vplatz
\exercise
Show that semilinear languages have the following pumping property: 
{\it For every semilinear set $V \subseteq \omega^n$ there exists a 
number $n$ such that if $\vec{v} \in V$ has length $\geq n$, there 
exist $\vec{w}$ and $\vec{x}$ such that $\vec{v} = \vec{w} + \vec{x}$ 
and $\vec{w} + \omega\vec{x} \subseteq V$.}
%%%
\vplatz
\exercise
\label{ex:omega}
Let $\Omega \subseteq \omega$. Let $V_{\Omega} \subseteq \omega^2$ 
be defined by
%%
\begin{equation}
V_{\Omega} := \{\auf m, n\zu : m \neq n \text{ or }m \in \Omega\}
\end{equation}
%%%
Show that $V_{\Omega}$ satisfies the pumping property of the previous 
exercise. Show further that $V_{\Omega}$ is semilinear iff $\Omega$ is. 
%%%
\vplatz
\exercise
%%%
\index{Presburger Arithmetic}%%%
%%%
Show that for every sentence $\varphi$ of Presburger Arithmetic 
it is decidable whether or not it is true in $\BZ$. 
{\it Hint.} Use quantifiers elimination and the fact that the 
elimination is constructive.
